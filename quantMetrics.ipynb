{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "import nltk\n",
    "import ast\n",
    "nltk.download('wordnet')\n",
    "from gensim import corpora, models\n",
    "# Importing the required libraries.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle, zlib\n",
    "from random import sample\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# Show graph\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from numpy import array\n",
    "import gensim.corpora as corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_index(res_ids,vectors,ids):\n",
    "    result =[]\n",
    "    ids = list(ids)\n",
    "    for i in res_ids:\n",
    "        if i in ids:\n",
    "            result.append(vectors[ids.index(i)])\n",
    "        else:\n",
    "            print(i,\"Id not found\")\n",
    "    return result           \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_indice(res_ids,vectors,ids):\n",
    "    result =[]\n",
    "    ids = list(ids)\n",
    "    for i in res_ids:\n",
    "        if i in ids:\n",
    "            result.append(vectors[ids.index(i)])\n",
    "        else:\n",
    "            print(i,\"Id not found\")\n",
    "      \n",
    "    return result       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "def lemmatize_stemming(text):\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def eucledian_distance(vec1,vec2):\n",
    "    a = np.median(np.array(vec1),axis=0)\n",
    "    b = np.median(np.array(vec2),axis=0)\n",
    "    a = np.reshape(a, (1, -1))\n",
    "    b = np.reshape(b, (1, -1))\n",
    "    euc_sim = norm(a-b)\n",
    "    return euc_sim\n",
    "all_rese=[]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collection: Agriculture\n",
      "\n",
      "Collection: Development\n",
      "\n",
      "Collection: Environment\n",
      "\n",
      "Collection: Industrialization\n",
      "\n",
      "Collection: Lifestyle\n",
      " Label               Agri  Dev  Env  Ind  Life \n",
      " Unemp  Slow vs Average 4.16 3.71 4.55 5.37 4.96\n",
      " Unemp  Slow vs Fast 3.9 5.43 4.67 3.98 4.85\n",
      " Unemp  Average vs Fast 5.11 5.57 5.58 5.19 3.9\n",
      " Agri   Slow vs Average 3.76 4.02 4.35 3.89 4.4\n",
      " Agri   Slow vs Fast 5.4 4.09 4.91 4.8 4.2\n",
      " Agri   Average vs Fast 5.21 4.35 4.0 4.34 4.76\n",
      "NonAgri Slow vs Average 5.83 6.09 5.24 6.18 6.45\n",
      "NonAgri Slow vs Fast 5.66 5.63 4.71 5.3 5.47\n",
      "NonAgri Average vs Fast 4.87 4.76 5.44 6.39 5.35\n"
     ]
    }
   ],
   "source": [
    "#Tf idf\n",
    "import pandas as pd\n",
    "datasets = ['dataset_agriculture', 'dataset_development', 'dataset_environment', 'dataset_industrialization', 'dataset_lifestyle']\n",
    "model_names = ['model_agriculture', 'model_development', 'model_environment', 'model_industrialization', 'model_lifestyle']\n",
    "final_res_all = []\n",
    "for dataset, model in zip(datasets,model_names):\n",
    "    dataset_name = dataset\n",
    "    # Printing the collection name.\n",
    "    collection_name = dataset[8:]\n",
    "    print('\\nCollection:',collection_name.capitalize())\n",
    "    # Loading the dataset and the model from the drive.\n",
    "    file = open('Datasets/'+dataset, 'rb')\n",
    "    dataset = pickle.loads(zlib.decompress(pickle.load(file)))\n",
    "    file.close()\n",
    "    model = Doc2Vec.load('Models/'+model)\n",
    "    # Collecting the article_ids, and corresponding article_vectors for each class.\n",
    "    temp_ids = [set() for _ in range(9)]\n",
    "    temp_vectors = [[] for _ in range(9)]\n",
    "    temp_datasets = [[] for _ in range(9)]\n",
    "    for i in dataset:\n",
    "        if i[6]=='Unemp' and i[-1]=='Slow':\n",
    "            if i[0] not in temp_ids[0]:\n",
    "                temp_ids[0].add(i[0])\n",
    "                temp_vectors[0].append(model.docvecs[i[0]])\n",
    "                temp_datasets[0].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Unemp' and i[-1]=='Average':\n",
    "            if i[0] not in temp_ids[1]:\n",
    "                temp_ids[1].add(i[0])\n",
    "                temp_vectors[1].append(model.docvecs[i[0]])\n",
    "                temp_datasets[1].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Unemp' and i[-1]=='Fast':\n",
    "            if i[0] not in temp_ids[2]:\n",
    "                temp_ids[2].add(i[0])\n",
    "                temp_vectors[2].append(model.docvecs[i[0]])\n",
    "                temp_datasets[2].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Agri' and i[-1]=='Slow':\n",
    "            if i[0] not in temp_ids[3]:\n",
    "                temp_ids[3].add(i[0])\n",
    "                temp_vectors[3].append(model.docvecs[i[0]])\n",
    "                temp_datasets[3].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Agri' and i[-1]=='Average':\n",
    "            if i[0] not in temp_ids[4]:\n",
    "                temp_ids[4].add(i[0])\n",
    "                temp_vectors[4].append(model.docvecs[i[0]])\n",
    "                temp_datasets[4].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Agri' and i[-1]=='Fast':\n",
    "            if i[0] not in temp_ids[5]:\n",
    "                temp_ids[5].add(i[0])\n",
    "                temp_vectors[5].append(model.docvecs[i[0]])\n",
    "                temp_datasets[5].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Non Agri' and i[-1]=='Slow':\n",
    "            if i[0] not in temp_ids[6]:\n",
    "                temp_ids[6].add(i[0])\n",
    "                temp_vectors[6].append(model.docvecs[i[0]])\n",
    "                temp_datasets[6].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Non Agri' and i[-1]=='Average':\n",
    "            if i[0] not in temp_ids[7]:\n",
    "                temp_ids[7].add(i[0])\n",
    "                temp_vectors[7].append(model.docvecs[i[0]])\n",
    "                temp_datasets[7].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Non Agri' and i[-1]=='Fast':\n",
    "            if i[0] not in temp_ids[8]:\n",
    "                temp_ids[8].add(i[0])\n",
    "                temp_vectors[8].append(model.docvecs[i[0]])\n",
    "                temp_datasets[8].append([i[0],model.docvecs[i[0]]])\n",
    "    names = ['unemp_avg_id','unemp_slow_id','unemp_fast_id','agri_avg_id','agri_slow_id','agri_fast_id','non_agri_avg_id','non_agri_slow_id','non_agri_fast_id']\n",
    "    df = pd.read_excel('RS/'+collection_name+'_ids.xlsx')\n",
    "    all_val = []\n",
    "    for i in [0,3,6]:\n",
    "        voc1 = (read_index(list(df[names[i]]),temp_vectors[i],temp_ids[i]))\n",
    "        voc2 = (read_index(list(df[names[i+1]]),temp_vectors[i+1],temp_ids[i+1]))\n",
    "        voc3 = (read_index(list(df[names[i+2]]),temp_vectors[i+2],temp_ids[i+2]))\n",
    "        lst = [eucledian_distance(voc1,voc2),eucledian_distance(voc3,voc2),eucledian_distance(voc1,voc3)]\n",
    "        all_val.append(lst)\n",
    "    final_res_all.append(all_val)\n",
    "all_rese.append(final_res_all)\n",
    "names = [\"Slow vs Average\",\"Slow vs Fast\",\"Average vs Fast\"]\n",
    "emp = [\" Unemp \",\" Agri  \",\"NonAgri\"]\n",
    "print(\" Label              \",\"Agri \",\"Dev \",\"Env \",\"Ind \",\"Life \")\n",
    "for j in range(3):\n",
    "    print(emp[0],names[j],round(final_res_all[0][0][j],2),round(final_res_all[1][0][j],2),round(final_res_all[2][0][j],2),round(final_res_all[3][0][j],2),round(final_res_all[4][0][j],2))\n",
    "\n",
    "for j in range(3):\n",
    "    print(emp[1],names[j],round(final_res_all[0][1][j],2),round(final_res_all[1][1][j],2),round(final_res_all[2][1][j],2),round(final_res_all[3][1][j],2),round(final_res_all[4][1][j],2))\n",
    "\n",
    "for j in range(3):\n",
    "    print(emp[2],names[j],round(final_res_all[0][2][j],2),round(final_res_all[1][2][j],2),round(final_res_all[2][2][j],2),round(final_res_all[3][2][j],2),round(final_res_all[4][2][j],2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collection: Agriculture\n",
      "\n",
      "Collection: Development\n",
      "\n",
      "Collection: Environment\n",
      "\n",
      "Collection: Industrialization\n",
      "\n",
      "Collection: Lifestyle\n",
      " Label               Agri  Dev  Env  Ind  Life \n",
      " Unemp  Slow vs Average 5.38 4.3 5.12 5.29 5.34\n",
      " Unemp  Slow vs Fast 4.33 4.24 4.8 4.86 5.05\n",
      " Unemp  Average vs Fast 4.54 4.2 5.72 5.63 4.8\n",
      " Agri   Slow vs Average 4.24 5.07 3.99 4.65 3.98\n",
      " Agri   Slow vs Fast 4.88 4.55 4.41 5.16 5.46\n",
      " Agri   Average vs Fast 4.66 5.16 4.11 4.67 4.86\n",
      "NonAgri Slow vs Average 5.61 6.31 5.96 5.93 4.89\n",
      "NonAgri Slow vs Fast 5.04 5.33 6.53 5.2 4.34\n",
      "NonAgri Average vs Fast 5.7 5.89 4.2 6.79 5.45\n"
     ]
    }
   ],
   "source": [
    "## DocTag2Vec\n",
    "import pandas as pd\n",
    "datasets = ['dataset_agriculture', 'dataset_development', 'dataset_environment', 'dataset_industrialization', 'dataset_lifestyle']\n",
    "model_names = ['model_agriculture', 'model_development', 'model_environment', 'model_industrialization', 'model_lifestyle']\n",
    "final_res_all = []\n",
    "for dataset, model in zip(datasets,model_names):\n",
    "    dataset_name = dataset\n",
    "    # Printing the collection name.\n",
    "    collection_name = dataset[8:]\n",
    "    print('\\nCollection:',collection_name.capitalize())\n",
    "    # Loading the dataset and the model from the drive.\n",
    "    file = open('../Datasets/newADIdataset/'+dataset, 'rb')\n",
    "    dataset = pickle.loads(zlib.decompress(pickle.load(file)))\n",
    "    file.close()\n",
    "    model = Doc2Vec.load('../Datasets/newADImodels/'+model)\n",
    "\n",
    "    # Collecting the article_ids, and corresponding article_vectors for each class.\n",
    "    temp_ids = [set() for _ in range(9)]\n",
    "    temp_vectors = [[] for _ in range(9)]\n",
    "    temp_datasets = [[] for _ in range(9)]\n",
    "    for i in dataset:\n",
    "        if i[6]=='Unemp' and i[-1]=='Slow':\n",
    "            if i[0] not in temp_ids[0]:\n",
    "                temp_ids[0].add(i[0])\n",
    "                temp_vectors[0].append(model.docvecs[i[0]])\n",
    "                temp_datasets[0].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Unemp' and i[-1]=='Average':\n",
    "            if i[0] not in temp_ids[1]:\n",
    "                temp_ids[1].add(i[0])\n",
    "                temp_vectors[1].append(model.docvecs[i[0]])\n",
    "                temp_datasets[1].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Unemp' and i[-1]=='Fast':\n",
    "            if i[0] not in temp_ids[2]:\n",
    "                temp_ids[2].add(i[0])\n",
    "                temp_vectors[2].append(model.docvecs[i[0]])\n",
    "                temp_datasets[2].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Agri' and i[-1]=='Slow':\n",
    "            if i[0] not in temp_ids[3]:\n",
    "                temp_ids[3].add(i[0])\n",
    "                temp_vectors[3].append(model.docvecs[i[0]])\n",
    "                temp_datasets[3].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Agri' and i[-1]=='Average':\n",
    "            if i[0] not in temp_ids[4]:\n",
    "                temp_ids[4].add(i[0])\n",
    "                temp_vectors[4].append(model.docvecs[i[0]])\n",
    "                temp_datasets[4].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Agri' and i[-1]=='Fast':\n",
    "            if i[0] not in temp_ids[5]:\n",
    "                temp_ids[5].add(i[0])\n",
    "                temp_vectors[5].append(model.docvecs[i[0]])\n",
    "                temp_datasets[5].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Non Agri' and i[-1]=='Slow':\n",
    "            if i[0] not in temp_ids[6]:\n",
    "                temp_ids[6].add(i[0])\n",
    "                temp_vectors[6].append(model.docvecs[i[0]])\n",
    "                temp_datasets[6].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Non Agri' and i[-1]=='Average':\n",
    "            if i[0] not in temp_ids[7]:\n",
    "                temp_ids[7].add(i[0])\n",
    "                temp_vectors[7].append(model.docvecs[i[0]])\n",
    "                temp_datasets[7].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Non Agri' and i[-1]=='Fast':\n",
    "            if i[0] not in temp_ids[8]:\n",
    "                temp_ids[8].add(i[0])\n",
    "                temp_vectors[8].append(model.docvecs[i[0]])\n",
    "                temp_datasets[8].append([i[0],model.docvecs[i[0]]])\n",
    "    names = ['unemp_avg_id','unemp_slow_id','unemp_fast_id','agri_avg_id','agri_slow_id','agri_fast_id','non_agri_avg_id','non_agri_slow_id','non_agri_fast_id']\n",
    "    df = pd.read_excel('DocTag2Vec/'+collection_name+'_ids.xlsx')\n",
    "    all_val = []\n",
    "    for i in [0,3,6]:\n",
    "        voc1 = (read_index(list(df[names[i]]),temp_vectors[i],temp_ids[i]))\n",
    "        voc2 = (read_index(list(df[names[i+1]]),temp_vectors[i+1],temp_ids[i+1]))\n",
    "        voc3 = (read_index(list(df[names[i+2]]),temp_vectors[i+2],temp_ids[i+2]))\n",
    "        lst = [eucledian_distance(voc1,voc2),eucledian_distance(voc3,voc2),eucledian_distance(voc1,voc3)]\n",
    "        all_val.append(lst)\n",
    "    final_res_all.append(all_val)\n",
    "all_rese.append(final_res_all)\n",
    "names = [\"Slow vs Average\",\"Slow vs Fast\",\"Average vs Fast\"]\n",
    "emp = [\" Unemp \",\" Agri  \",\"NonAgri\"]\n",
    "print(\" Label              \",\"Agri \",\"Dev \",\"Env \",\"Ind \",\"Life \")\n",
    "for j in range(3):\n",
    "    print(emp[0],names[j],round(final_res_all[0][0][j],2),round(final_res_all[1][0][j],2),round(final_res_all[2][0][j],2),round(final_res_all[3][0][j],2),round(final_res_all[4][0][j],2))\n",
    "\n",
    "for j in range(3):\n",
    "    print(emp[1],names[j],round(final_res_all[0][1][j],2),round(final_res_all[1][1][j],2),round(final_res_all[2][1][j],2),round(final_res_all[3][1][j],2),round(final_res_all[4][1][j],2))\n",
    "\n",
    "for j in range(3):\n",
    "    print(emp[2],names[j],round(final_res_all[0][2][j],2),round(final_res_all[1][2][j],2),round(final_res_all[2][2][j],2),round(final_res_all[3][2][j],2),round(final_res_all[4][2][j],2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collection: Agriculture\n",
      "\n",
      "Collection: Development\n",
      "\n",
      "Collection: Environment\n",
      "\n",
      "Collection: Industrialization\n",
      "\n",
      "Collection: Lifestyle\n",
      " Label               Agri  Dev  Env  Ind  Life \n",
      " Unemp  Slow vs Average 4.22 3.96 5.49 5.83 5.03\n",
      " Unemp  Slow vs Fast 3.49 4.29 3.85 4.3 4.38\n",
      " Unemp  Average vs Fast 4.24 4.38 5.57 4.89 4.71\n",
      " Agri   Slow vs Average 3.97 4.25 4.36 4.74 5.82\n",
      " Agri   Slow vs Fast 4.74 4.23 4.72 4.99 5.49\n",
      " Agri   Average vs Fast 4.56 5.07 4.33 5.8 4.48\n",
      "NonAgri Slow vs Average 6.48 5.73 4.89 4.62 5.53\n",
      "NonAgri Slow vs Fast 4.94 4.95 3.92 4.96 4.85\n",
      "NonAgri Average vs Fast 5.29 5.19 5.47 5.61 4.58\n"
     ]
    }
   ],
   "source": [
    "## LDA\n",
    "import pandas as pd\n",
    "datasets = ['dataset_agriculture', 'dataset_development', 'dataset_environment', 'dataset_industrialization', 'dataset_lifestyle']\n",
    "model_names = ['model_agriculture', 'model_development', 'model_environment', 'model_industrialization', 'model_lifestyle']\n",
    "final_res_all = []\n",
    "for dataset, model in zip(datasets,model_names):\n",
    "    dataset_name = dataset\n",
    "    # Printing the collection name.\n",
    "    collection_name = dataset[8:]\n",
    "    print('\\nCollection:',collection_name.capitalize())\n",
    "    # Loading the dataset and the model from the drive.\n",
    "    file = open('Datasets/'+dataset, 'rb')\n",
    "    dataset = pickle.loads(zlib.decompress(pickle.load(file)))\n",
    "    file.close()\n",
    "    model = Doc2Vec.load('Models/'+model)\n",
    "    # Collecting the article_ids, and corresponding article_vectors for each class.\n",
    "    temp_ids = [set() for _ in range(9)]\n",
    "    temp_vectors = [[] for _ in range(9)]\n",
    "    temp_datasets = [[] for _ in range(9)]\n",
    "    for i in dataset:\n",
    "        if i[6]=='Unemp' and i[-1]=='Slow':\n",
    "            if i[0] not in temp_ids[0]:\n",
    "                temp_ids[0].add(i[0])\n",
    "                temp_vectors[0].append(model.docvecs[i[0]])\n",
    "                temp_datasets[0].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Unemp' and i[-1]=='Average':\n",
    "            if i[0] not in temp_ids[1]:\n",
    "                temp_ids[1].add(i[0])\n",
    "                temp_vectors[1].append(model.docvecs[i[0]])\n",
    "                temp_datasets[1].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Unemp' and i[-1]=='Fast':\n",
    "            if i[0] not in temp_ids[2]:\n",
    "                temp_ids[2].add(i[0])\n",
    "                temp_vectors[2].append(model.docvecs[i[0]])\n",
    "                temp_datasets[2].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Agri' and i[-1]=='Slow':\n",
    "            if i[0] not in temp_ids[3]:\n",
    "                temp_ids[3].add(i[0])\n",
    "                temp_vectors[3].append(model.docvecs[i[0]])\n",
    "                temp_datasets[3].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Agri' and i[-1]=='Average':\n",
    "            if i[0] not in temp_ids[4]:\n",
    "                temp_ids[4].add(i[0])\n",
    "                temp_vectors[4].append(model.docvecs[i[0]])\n",
    "                temp_datasets[4].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Agri' and i[-1]=='Fast':\n",
    "            if i[0] not in temp_ids[5]:\n",
    "                temp_ids[5].add(i[0])\n",
    "                temp_vectors[5].append(model.docvecs[i[0]])\n",
    "                temp_datasets[5].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Non Agri' and i[-1]=='Slow':\n",
    "            if i[0] not in temp_ids[6]:\n",
    "                temp_ids[6].add(i[0])\n",
    "                temp_vectors[6].append(model.docvecs[i[0]])\n",
    "                temp_datasets[6].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Non Agri' and i[-1]=='Average':\n",
    "            if i[0] not in temp_ids[7]:\n",
    "                temp_ids[7].add(i[0])\n",
    "                temp_vectors[7].append(model.docvecs[i[0]])\n",
    "                temp_datasets[7].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Non Agri' and i[-1]=='Fast':\n",
    "            if i[0] not in temp_ids[8]:\n",
    "                temp_ids[8].add(i[0])\n",
    "                temp_vectors[8].append(model.docvecs[i[0]])\n",
    "                temp_datasets[8].append([i[0],model.docvecs[i[0]]])\n",
    "    names = ['unemp_avg_id','unemp_slow_id','unemp_fast_id','agri_avg_id','agri_slow_id','agri_fast_id','non_agri_avg_id','non_agri_slow_id','non_agri_fast_id']\n",
    "    df = pd.read_excel('LDA/'+collection_name+'_ids.xlsx')\n",
    "    all_val=[]\n",
    "    for i in [0,3,6]:\n",
    "        voc1 = (read_index(list(df[names[i]]),temp_vectors[i],temp_ids[i]))\n",
    "        voc2 = (read_index(list(df[names[i+1]]),temp_vectors[i+1],temp_ids[i+1]))\n",
    "        voc3 = (read_index(list(df[names[i+2]]),temp_vectors[i+2],temp_ids[i+2]))\n",
    "        lst = [eucledian_distance(voc1,voc2),eucledian_distance(voc3,voc2),eucledian_distance(voc1,voc3)]\n",
    "        all_val.append(lst)\n",
    "    final_res_all.append(all_val)\n",
    "all_rese.append(final_res_all)\n",
    "names = [\"Slow vs Average\",\"Slow vs Fast\",\"Average vs Fast\"]\n",
    "emp = [\" Unemp \",\" Agri  \",\"NonAgri\"]\n",
    "print(\" Label              \",\"Agri \",\"Dev \",\"Env \",\"Ind \",\"Life \")\n",
    "for j in range(3):\n",
    "    print(emp[0],names[j],round(final_res_all[0][0][j],2),round(final_res_all[1][0][j],2),round(final_res_all[2][0][j],2),round(final_res_all[3][0][j],2),round(final_res_all[4][0][j],2))\n",
    "\n",
    "for j in range(3):\n",
    "    print(emp[1],names[j],round(final_res_all[0][1][j],2),round(final_res_all[1][1][j],2),round(final_res_all[2][1][j],2),round(final_res_all[3][1][j],2),round(final_res_all[4][1][j],2))\n",
    "\n",
    "for j in range(3):\n",
    "    print(emp[2],names[j],round(final_res_all[0][2][j],2),round(final_res_all[1][2][j],2),round(final_res_all[2][2][j],2),round(final_res_all[3][2][j],2),round(final_res_all[4][2][j],2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Label               Agri  Dev  Env  Ind  Life \n",
      "doc2ec   Unemp  Slow vs Fast 4.33 4.24 4.8 4.86 5.05\n",
      "tf-idf   Unemp  Slow vs Fast 3.9 5.43 4.67 3.98 4.85\n",
      "lda      Unemp  Slow vs Fast 3.49 4.29 3.85 4.3 4.38\n",
      "\n",
      "\n",
      "\n",
      "doc2vec   Agri   Slow vs Fast 4.88 4.55 4.41 5.16 5.46\n",
      "tf-idf   Agri   Slow vs Fast 5.4 4.09 4.91 4.8 4.2\n",
      "lda      Agri   Slow vs Fast 4.74 4.23 4.72 4.99 5.49\n",
      "\n",
      "\n",
      "\n",
      "doc2vec  NonAgri Slow vs Fast 5.04 5.33 6.53 5.2 4.34\n",
      "tf-idf  NonAgri Slow vs Fast 5.66 5.63 4.71 5.3 5.47\n",
      "lda    NonAgri Slow vs Fast 4.94 4.95 3.92 4.96 4.85\n"
     ]
    }
   ],
   "source": [
    "names = [\"Slow vs Average\",\"Slow vs Fast\",\"Average vs Fast\"]\n",
    "emp = [\" Unemp \",\" Agri  \",\"NonAgri\"]\n",
    "\n",
    "print(\" Label              \",\"Agri \",\"Dev \",\"Env \",\"Ind \",\"Life \")\n",
    "final_res_all1 = all_rese[0]\n",
    "final_res_all2 = all_rese[1]\n",
    "final_res_all3 = all_rese[2]\n",
    "\n",
    "for j in [1]:#range(3):\n",
    "    print('doc2ec ',emp[0],names[j],round(final_res_all2[0][0][j],2),round(final_res_all2[1][0][j],2),round(final_res_all2[2][0][j],2),round(final_res_all2[3][0][j],2),round(final_res_all2[4][0][j],2))\n",
    "    print('tf-idf ',emp[0],names[j],round(final_res_all1[0][0][j],2),round(final_res_all1[1][0][j],2),round(final_res_all1[2][0][j],2),round(final_res_all1[3][0][j],2),round(final_res_all1[4][0][j],2))\n",
    "    print('lda    ',emp[0],names[j],round(final_res_all3[0][0][j],2),round(final_res_all3[1][0][j],2),round(final_res_all3[2][0][j],2),round(final_res_all3[3][0][j],2),round(final_res_all3[4][0][j],2))\n",
    "print('\\n\\n')\n",
    "\n",
    "for j in [1]:#range(3):\n",
    "    print('doc2vec ',emp[1],names[j],round(final_res_all2[0][1][j],2),round(final_res_all2[1][1][j],2),round(final_res_all2[2][1][j],2),round(final_res_all2[3][1][j],2),round(final_res_all2[4][1][j],2))    \n",
    "    print('tf-idf ',emp[1],names[j],round(final_res_all1[0][1][j],2),round(final_res_all1[1][1][j],2),round(final_res_all1[2][1][j],2),round(final_res_all1[3][1][j],2),round(final_res_all1[4][1][j],2))\n",
    "    print('lda    ',emp[1],names[j],round(final_res_all3[0][1][j],2),round(final_res_all3[1][1][j],2),round(final_res_all3[2][1][j],2),round(final_res_all3[3][1][j],2),round(final_res_all3[4][1][j],2))\n",
    "print('\\n\\n')\n",
    "for j in [1]:#range(3):\n",
    "    print('doc2vec ',emp[2],names[j],round(final_res_all2[0][2][j],2),round(final_res_all2[1][2][j],2),round(final_res_all2[2][2][j],2),round(final_res_all2[3][2][j],2),round(final_res_all2[4][2][j],2))\n",
    "    print('tf-idf ',emp[2],names[j],round(final_res_all1[0][2][j],2),round(final_res_all1[1][2][j],2),round(final_res_all1[2][2][j],2),round(final_res_all1[3][2][j],2),round(final_res_all1[4][2][j],2))\n",
    "    print('lda   ',emp[2],names[j],round(final_res_all3[0][2][j],2),round(final_res_all3[1][2][j],2),round(final_res_all3[2][2][j],2),round(final_res_all3[3][2][j],2),round(final_res_all3[4][2][j],2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global centroid similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def global_similarity(vec1,vec2):\n",
    "    a = np.median(np.array(vec1),axis=0)\n",
    "    b = np.median(np.array(vec2),axis=0)\n",
    "    a = np.reshape(a, (1, -1))\n",
    "    b = np.reshape(b, (1, -1))\n",
    "    cos_sim = (cosine_similarity(a,b))\n",
    "    return (cos_sim[0][0]+1)/2\n",
    "    \n",
    "all_resg = []  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collection: Agriculture\n",
      "\n",
      "Collection: Development\n",
      "\n",
      "Collection: Environment\n",
      "\n",
      "Collection: Industrialization\n",
      "\n",
      "Collection: Lifestyle\n",
      " Label               Agri  Dev  Env  Ind  Life \n",
      " Unemp  Slow vs Average 0.75 0.83 0.67 0.65 0.72\n",
      " Unemp  Slow vs Fast 0.77 0.61 0.76 0.8 0.7\n",
      " Unemp  Average vs Fast 0.65 0.58 0.67 0.69 0.79\n",
      " Agri   Slow vs Average 0.72 0.79 0.77 0.89 0.78\n",
      " Agri   Slow vs Fast 0.67 0.72 0.65 0.77 0.74\n",
      " Agri   Average vs Fast 0.72 0.71 0.8 0.86 0.74\n",
      "NonAgri Slow vs Average 0.48 0.43 0.42 0.6 0.48\n",
      "NonAgri Slow vs Fast 0.37 0.37 0.44 0.56 0.47\n",
      "NonAgri Average vs Fast 0.49 0.42 0.36 0.43 0.47\n"
     ]
    }
   ],
   "source": [
    "#tf idf\n",
    "import pandas as pd\n",
    "datasets = ['dataset_agriculture', 'dataset_development', 'dataset_environment', 'dataset_industrialization', 'dataset_lifestyle']\n",
    "model_names = ['model_agriculture', 'model_development', 'model_environment', 'model_industrialization', 'model_lifestyle']\n",
    "final_res_all = []\n",
    "for dataset, model in zip(datasets,model_names):\n",
    "    dataset_name = dataset\n",
    "    # Printing the collection name.\n",
    "    collection_name = dataset[8:]\n",
    "    print('\\nCollection:',collection_name.capitalize())\n",
    "    # Loading the dataset and the model from the drive.\n",
    "    file = open('Datasets/'+dataset, 'rb')\n",
    "    dataset = pickle.loads(zlib.decompress(pickle.load(file)))\n",
    "    file.close()\n",
    "    model = Doc2Vec.load('Models/'+model)\n",
    "\n",
    "    # Collecting the article_ids, and corresponding article_vectors for each class.\n",
    "    temp_ids = [set() for _ in range(9)]\n",
    "    temp_vectors = [[] for _ in range(9)]\n",
    "    temp_datasets = [[] for _ in range(9)]\n",
    "    for i in dataset:\n",
    "        if i[6]=='Unemp' and i[-1]=='Slow':\n",
    "            if i[0] not in temp_ids[0]:\n",
    "                temp_ids[0].add(i[0])\n",
    "                temp_vectors[0].append(model.docvecs[i[0]])\n",
    "                temp_datasets[0].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Unemp' and i[-1]=='Average':\n",
    "            if i[0] not in temp_ids[1]:\n",
    "                temp_ids[1].add(i[0])\n",
    "                temp_vectors[1].append(model.docvecs[i[0]])\n",
    "                temp_datasets[1].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Unemp' and i[-1]=='Fast':\n",
    "            if i[0] not in temp_ids[2]:\n",
    "                temp_ids[2].add(i[0])\n",
    "                temp_vectors[2].append(model.docvecs[i[0]])\n",
    "                temp_datasets[2].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Agri' and i[-1]=='Slow':\n",
    "            if i[0] not in temp_ids[3]:\n",
    "                temp_ids[3].add(i[0])\n",
    "                temp_vectors[3].append(model.docvecs[i[0]])\n",
    "                temp_datasets[3].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Agri' and i[-1]=='Average':\n",
    "            if i[0] not in temp_ids[4]:\n",
    "                temp_ids[4].add(i[0])\n",
    "                temp_vectors[4].append(model.docvecs[i[0]])\n",
    "                temp_datasets[4].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Agri' and i[-1]=='Fast':\n",
    "            if i[0] not in temp_ids[5]:\n",
    "                temp_ids[5].add(i[0])\n",
    "                temp_vectors[5].append(model.docvecs[i[0]])\n",
    "                temp_datasets[5].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Non Agri' and i[-1]=='Slow':\n",
    "            if i[0] not in temp_ids[6]:\n",
    "                temp_ids[6].add(i[0])\n",
    "                temp_vectors[6].append(model.docvecs[i[0]])\n",
    "                temp_datasets[6].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Non Agri' and i[-1]=='Average':\n",
    "            if i[0] not in temp_ids[7]:\n",
    "                temp_ids[7].add(i[0])\n",
    "                temp_vectors[7].append(model.docvecs[i[0]])\n",
    "                temp_datasets[7].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Non Agri' and i[-1]=='Fast':\n",
    "            if i[0] not in temp_ids[8]:\n",
    "                temp_ids[8].add(i[0])\n",
    "                temp_vectors[8].append(model.docvecs[i[0]])\n",
    "                temp_datasets[8].append([i[0],model.docvecs[i[0]]])\n",
    "    names = ['unemp_avg_id','unemp_slow_id','unemp_fast_id','agri_avg_id','agri_slow_id','agri_fast_id','non_agri_avg_id','non_agri_slow_id','non_agri_fast_id']\n",
    "    df = pd.read_excel('RS/'+collection_name+'_ids.xlsx')\n",
    "    all_val = []\n",
    "    for i in [0,3,6]:\n",
    "        voc1 = (read_index(list(df[names[i]]),temp_vectors[i],temp_ids[i]))\n",
    "        voc2 = (read_index(list(df[names[i+1]]),temp_vectors[i+1],temp_ids[i+1]))\n",
    "        voc3 = (read_index(list(df[names[i+2]]),temp_vectors[i+2],temp_ids[i+2]))\n",
    "        lst = [global_similarity(voc1,voc2),global_similarity(voc3,voc2),global_similarity(voc1,voc3)]\n",
    "        all_val.append(lst)\n",
    "    final_res_all.append(all_val)\n",
    "all_resg.append(final_res_all)\n",
    "names = [\"Slow vs Average\",\"Slow vs Fast\",\"Average vs Fast\"]\n",
    "emp = [\" Unemp \",\" Agri  \",\"NonAgri\"]\n",
    "print(\" Label              \",\"Agri \",\"Dev \",\"Env \",\"Ind \",\"Life \")\n",
    "for j in range(3):\n",
    "    print(emp[0],names[j],round(final_res_all[0][0][j],2),round(final_res_all[1][0][j],2),round(final_res_all[2][0][j],2),round(final_res_all[3][0][j],2),round(final_res_all[4][0][j],2))\n",
    "\n",
    "for j in range(3):\n",
    "    print(emp[1],names[j],round(final_res_all[0][1][j],2),round(final_res_all[1][1][j],2),round(final_res_all[2][1][j],2),round(final_res_all[3][1][j],2),round(final_res_all[4][1][j],2))\n",
    "\n",
    "for j in range(3):\n",
    "    print(emp[2],names[j],round(final_res_all[0][2][j],2),round(final_res_all[1][2][j],2),round(final_res_all[2][2][j],2),round(final_res_all[3][2][j],2),round(final_res_all[4][2][j],2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collection: Agriculture\n",
      "\n",
      "Collection: Development\n",
      "\n",
      "Collection: Environment\n",
      "\n",
      "Collection: Industrialization\n",
      "\n",
      "Collection: Lifestyle\n",
      " Label               Agri  Dev  Env  Ind  Life \n",
      " Unemp  Slow vs Average 0.59 0.71 0.66 0.74 0.63\n",
      " Unemp  Slow vs Fast 0.66 0.71 0.67 0.76 0.61\n",
      " Unemp  Average vs Fast 0.66 0.67 0.65 0.71 0.69\n",
      " Agri   Slow vs Average 0.74 0.65 0.8 0.81 0.84\n",
      " Agri   Slow vs Fast 0.64 0.58 0.66 0.73 0.65\n",
      " Agri   Average vs Fast 0.74 0.67 0.8 0.82 0.78\n",
      "NonAgri Slow vs Average 0.55 0.36 0.43 0.66 0.54\n",
      "NonAgri Slow vs Fast 0.44 0.43 0.29 0.51 0.44\n",
      "NonAgri Average vs Fast 0.48 0.34 0.61 0.38 0.42\n"
     ]
    }
   ],
   "source": [
    "### DocTag2Vec\n",
    "\n",
    "import pandas as pd\n",
    "datasets = ['dataset_agriculture', 'dataset_development', 'dataset_environment', 'dataset_industrialization', 'dataset_lifestyle']\n",
    "model_names = ['model_agriculture', 'model_development', 'model_environment', 'model_industrialization', 'model_lifestyle']\n",
    "final_res_all = []\n",
    "for dataset, model in zip(datasets,model_names):\n",
    "    dataset_name = dataset\n",
    "    # Printing the collection name.\n",
    "    collection_name = dataset[8:]\n",
    "    print('\\nCollection:',collection_name.capitalize())\n",
    "    # Loading the dataset and the model from the drive.\n",
    "    file = open('Datasets/'+dataset, 'rb')\n",
    "    dataset = pickle.loads(zlib.decompress(pickle.load(file)))\n",
    "    file.close()\n",
    "    model = Doc2Vec.load('Models/'+model)\n",
    "\n",
    "    # Collecting the article_ids, and corresponding article_vectors for each class.\n",
    "    temp_ids = [set() for _ in range(9)]\n",
    "    temp_vectors = [[] for _ in range(9)]\n",
    "    temp_datasets = [[] for _ in range(9)]\n",
    "    for i in dataset:\n",
    "        if i[6]=='Unemp' and i[-1]=='Slow':\n",
    "            if i[0] not in temp_ids[0]:\n",
    "                temp_ids[0].add(i[0])\n",
    "                temp_vectors[0].append(model.docvecs[i[0]])\n",
    "                temp_datasets[0].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Unemp' and i[-1]=='Average':\n",
    "            if i[0] not in temp_ids[1]:\n",
    "                temp_ids[1].add(i[0])\n",
    "                temp_vectors[1].append(model.docvecs[i[0]])\n",
    "                temp_datasets[1].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Unemp' and i[-1]=='Fast':\n",
    "            if i[0] not in temp_ids[2]:\n",
    "                temp_ids[2].add(i[0])\n",
    "                temp_vectors[2].append(model.docvecs[i[0]])\n",
    "                temp_datasets[2].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Agri' and i[-1]=='Slow':\n",
    "            if i[0] not in temp_ids[3]:\n",
    "                temp_ids[3].add(i[0])\n",
    "                temp_vectors[3].append(model.docvecs[i[0]])\n",
    "                temp_datasets[3].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Agri' and i[-1]=='Average':\n",
    "            if i[0] not in temp_ids[4]:\n",
    "                temp_ids[4].add(i[0])\n",
    "                temp_vectors[4].append(model.docvecs[i[0]])\n",
    "                temp_datasets[4].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Agri' and i[-1]=='Fast':\n",
    "            if i[0] not in temp_ids[5]:\n",
    "                temp_ids[5].add(i[0])\n",
    "                temp_vectors[5].append(model.docvecs[i[0]])\n",
    "                temp_datasets[5].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Non Agri' and i[-1]=='Slow':\n",
    "            if i[0] not in temp_ids[6]:\n",
    "                temp_ids[6].add(i[0])\n",
    "                temp_vectors[6].append(model.docvecs[i[0]])\n",
    "                temp_datasets[6].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Non Agri' and i[-1]=='Average':\n",
    "            if i[0] not in temp_ids[7]:\n",
    "                temp_ids[7].add(i[0])\n",
    "                temp_vectors[7].append(model.docvecs[i[0]])\n",
    "                temp_datasets[7].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Non Agri' and i[-1]=='Fast':\n",
    "            if i[0] not in temp_ids[8]:\n",
    "                temp_ids[8].add(i[0])\n",
    "                temp_vectors[8].append(model.docvecs[i[0]])\n",
    "                temp_datasets[8].append([i[0],model.docvecs[i[0]]])\n",
    "    names = ['unemp_avg_id','unemp_slow_id','unemp_fast_id','agri_avg_id','agri_slow_id','agri_fast_id','non_agri_avg_id','non_agri_slow_id','non_agri_fast_id']\n",
    "    df = pd.read_excel('DocTag2Vec/'+collection_name+'_ids.xlsx')\n",
    "    all_val = []\n",
    "    for i in [0,3,6]:\n",
    "        voc1 = (read_index(list(df[names[i]]),temp_vectors[i],temp_ids[i]))\n",
    "        voc2 = (read_index(list(df[names[i+1]]),temp_vectors[i+1],temp_ids[i+1]))\n",
    "        voc3 = (read_index(list(df[names[i+2]]),temp_vectors[i+2],temp_ids[i+2]))\n",
    "        lst = [global_similarity(voc1,voc2),global_similarity(voc3,voc2),global_similarity(voc1,voc3)]\n",
    "        all_val.append(lst)\n",
    "    final_res_all.append(all_val)\n",
    "all_resg.append(final_res_all)\n",
    "names = [\"Slow vs Average\",\"Slow vs Fast\",\"Average vs Fast\"]\n",
    "emp = [\" Unemp \",\" Agri  \",\"NonAgri\"]\n",
    "print(\" Label              \",\"Agri \",\"Dev \",\"Env \",\"Ind \",\"Life \")\n",
    "for j in range(3):\n",
    "    print(emp[0],names[j],round(final_res_all[0][0][j],2),round(final_res_all[1][0][j],2),round(final_res_all[2][0][j],2),round(final_res_all[3][0][j],2),round(final_res_all[4][0][j],2))\n",
    "\n",
    "for j in range(3):\n",
    "    print(emp[1],names[j],round(final_res_all[0][1][j],2),round(final_res_all[1][1][j],2),round(final_res_all[2][1][j],2),round(final_res_all[3][1][j],2),round(final_res_all[4][1][j],2))\n",
    "\n",
    "for j in range(3):\n",
    "    print(emp[2],names[j],round(final_res_all[0][2][j],2),round(final_res_all[1][2][j],2),round(final_res_all[2][2][j],2),round(final_res_all[3][2][j],2),round(final_res_all[4][2][j],2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collection: Agriculture\n",
      "\n",
      "Collection: Development\n",
      "\n",
      "Collection: Environment\n",
      "\n",
      "Collection: Industrialization\n",
      "\n",
      "Collection: Lifestyle\n",
      " Label               Agri  Dev  Env  Ind  Life \n",
      " Unemp  Slow vs Average 0.71 0.76 0.67 0.67 0.67\n",
      " Unemp  Slow vs Fast 0.78 0.66 0.78 0.76 0.71\n",
      " Unemp  Average vs Fast 0.72 0.65 0.68 0.77 0.71\n",
      " Agri   Slow vs Average 0.76 0.77 0.74 0.86 0.72\n",
      " Agri   Slow vs Fast 0.63 0.71 0.7 0.8 0.72\n",
      " Agri   Average vs Fast 0.71 0.66 0.73 0.79 0.81\n",
      "NonAgri Slow vs Average 0.43 0.43 0.53 0.71 0.42\n",
      "NonAgri Slow vs Fast 0.51 0.4 0.56 0.45 0.41\n",
      "NonAgri Average vs Fast 0.53 0.39 0.33 0.41 0.52\n"
     ]
    }
   ],
   "source": [
    "### LDA\n",
    "\n",
    "import pandas as pd\n",
    "datasets = ['dataset_agriculture', 'dataset_development', 'dataset_environment', 'dataset_industrialization', 'dataset_lifestyle']\n",
    "model_names = ['model_agriculture', 'model_development', 'model_environment', 'model_industrialization', 'model_lifestyle']\n",
    "final_res_all = []\n",
    "for dataset, model in zip(datasets,model_names):\n",
    "    dataset_name = dataset\n",
    "    # Printing the collection name.\n",
    "    collection_name = dataset[8:]\n",
    "    print('\\nCollection:',collection_name.capitalize())\n",
    "    # Loading the dataset and the model from the drive.\n",
    "    file = open('Datasets/'+dataset, 'rb')\n",
    "    dataset = pickle.loads(zlib.decompress(pickle.load(file)))\n",
    "    file.close()\n",
    "    model = Doc2Vec.load('Models/'+model)\n",
    "    # Collecting the article_ids, and corresponding article_vectors for each class.\n",
    "    temp_ids = [set() for _ in range(9)]\n",
    "    temp_vectors = [[] for _ in range(9)]\n",
    "    temp_datasets = [[] for _ in range(9)]\n",
    "    for i in dataset:\n",
    "        if i[6]=='Unemp' and i[-1]=='Slow':\n",
    "            if i[0] not in temp_ids[0]:\n",
    "                temp_ids[0].add(i[0])\n",
    "                temp_vectors[0].append(model.docvecs[i[0]])\n",
    "                temp_datasets[0].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Unemp' and i[-1]=='Average':\n",
    "            if i[0] not in temp_ids[1]:\n",
    "                temp_ids[1].add(i[0])\n",
    "                temp_vectors[1].append(model.docvecs[i[0]])\n",
    "                temp_datasets[1].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Unemp' and i[-1]=='Fast':\n",
    "            if i[0] not in temp_ids[2]:\n",
    "                temp_ids[2].add(i[0])\n",
    "                temp_vectors[2].append(model.docvecs[i[0]])\n",
    "                temp_datasets[2].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Agri' and i[-1]=='Slow':\n",
    "            if i[0] not in temp_ids[3]:\n",
    "                temp_ids[3].add(i[0])\n",
    "                temp_vectors[3].append(model.docvecs[i[0]])\n",
    "                temp_datasets[3].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Agri' and i[-1]=='Average':\n",
    "            if i[0] not in temp_ids[4]:\n",
    "                temp_ids[4].add(i[0])\n",
    "                temp_vectors[4].append(model.docvecs[i[0]])\n",
    "                temp_datasets[4].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Agri' and i[-1]=='Fast':\n",
    "            if i[0] not in temp_ids[5]:\n",
    "                temp_ids[5].add(i[0])\n",
    "                temp_vectors[5].append(model.docvecs[i[0]])\n",
    "                temp_datasets[5].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Non Agri' and i[-1]=='Slow':\n",
    "            if i[0] not in temp_ids[6]:\n",
    "                temp_ids[6].add(i[0])\n",
    "                temp_vectors[6].append(model.docvecs[i[0]])\n",
    "                temp_datasets[6].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Non Agri' and i[-1]=='Average':\n",
    "            if i[0] not in temp_ids[7]:\n",
    "                temp_ids[7].add(i[0])\n",
    "                temp_vectors[7].append(model.docvecs[i[0]])\n",
    "                temp_datasets[7].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Non Agri' and i[-1]=='Fast':\n",
    "            if i[0] not in temp_ids[8]:\n",
    "                temp_ids[8].add(i[0])\n",
    "                temp_vectors[8].append(model.docvecs[i[0]])\n",
    "                temp_datasets[8].append([i[0],model.docvecs[i[0]]])\n",
    "    names = ['unemp_avg_id','unemp_slow_id','unemp_fast_id','agri_avg_id','agri_slow_id','agri_fast_id','non_agri_avg_id','non_agri_slow_id','non_agri_fast_id']\n",
    "    df = pd.read_excel('LDA/'+collection_name+'_ids.xlsx')\n",
    "    all_val = []\n",
    "    for i in [0,3,6]:\n",
    "        voc1 = (read_index(list(df[names[i]]),temp_vectors[i],temp_ids[i]))\n",
    "        voc2 = (read_index(list(df[names[i+1]]),temp_vectors[i+1],temp_ids[i+1]))\n",
    "        voc3 = (read_index(list(df[names[i+2]]),temp_vectors[i+2],temp_ids[i+2]))\n",
    "        lst = [global_similarity(voc1,voc2),global_similarity(voc3,voc2),global_similarity(voc1,voc3)]\n",
    "        all_val.append(lst)\n",
    "    final_res_all.append(all_val)\n",
    "all_resg.append(final_res_all)\n",
    "names = [\"Slow vs Average\",\"Slow vs Fast\",\"Average vs Fast\"]\n",
    "emp = [\" Unemp \",\" Agri  \",\"NonAgri\"]\n",
    "print(\" Label              \",\"Agri \",\"Dev \",\"Env \",\"Ind \",\"Life \")\n",
    "for j in range(3):\n",
    "    print(emp[0],names[j],round(final_res_all[0][0][j],2),round(final_res_all[1][0][j],2),round(final_res_all[2][0][j],2),round(final_res_all[3][0][j],2),round(final_res_all[4][0][j],2))\n",
    "\n",
    "for j in range(3):\n",
    "    print(emp[1],names[j],round(final_res_all[0][1][j],2),round(final_res_all[1][1][j],2),round(final_res_all[2][1][j],2),round(final_res_all[3][1][j],2),round(final_res_all[4][1][j],2))\n",
    "\n",
    "for j in range(3):\n",
    "    print(emp[2],names[j],round(final_res_all[0][2][j],2),round(final_res_all[1][2][j],2),round(final_res_all[2][2][j],2),round(final_res_all[3][2][j],2),round(final_res_all[4][2][j],2))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Label               Agri  Dev  Env  Ind  Life \n",
      "doc2ec   Unemp  Slow vs Fast 0.66 0.71 0.67 0.76 0.61\n",
      "tf-idf   Unemp  Slow vs Fast 0.77 0.61 0.76 0.8 0.7\n",
      "lda      Unemp  Slow vs Fast 0.78 0.66 0.78 0.76 0.71\n",
      "\n",
      "\n",
      "\n",
      "doc2vec   Agri   Slow vs Fast 0.64 0.58 0.66 0.73 0.65\n",
      "tf-idf   Agri   Slow vs Fast 0.67 0.72 0.65 0.77 0.74\n",
      "lda      Agri   Slow vs Fast 0.63 0.71 0.7 0.8 0.72\n",
      "\n",
      "\n",
      "\n",
      "doc2vec  NonAgri Slow vs Fast 0.44 0.43 0.29 0.51 0.44\n",
      "tf-idf  NonAgri Slow vs Fast 0.37 0.37 0.44 0.56 0.47\n",
      "lda    NonAgri Slow vs Fast 0.51 0.4 0.56 0.45 0.41\n"
     ]
    }
   ],
   "source": [
    "names = [\"Slow vs Average\",\"Slow vs Fast\",\"Average vs Fast\"]\n",
    "emp = [\" Unemp \",\" Agri  \",\"NonAgri\"]\n",
    "\n",
    "print(\" Label              \",\"Agri \",\"Dev \",\"Env \",\"Ind \",\"Life \")\n",
    "final_res_all1 = all_resg[0]\n",
    "final_res_all2 = all_resg[1]\n",
    "final_res_all3 = all_resg[2]\n",
    "\n",
    "for j in [1]:#range(3):\n",
    "    print('doc2ec ',emp[0],names[j],round(final_res_all2[0][0][j],2),round(final_res_all2[1][0][j],2),round(final_res_all2[2][0][j],2),round(final_res_all2[3][0][j],2),round(final_res_all2[4][0][j],2))\n",
    "    print('tf-idf ',emp[0],names[j],round(final_res_all1[0][0][j],2),round(final_res_all1[1][0][j],2),round(final_res_all1[2][0][j],2),round(final_res_all1[3][0][j],2),round(final_res_all1[4][0][j],2))\n",
    "    print('lda    ',emp[0],names[j],round(final_res_all3[0][0][j],2),round(final_res_all3[1][0][j],2),round(final_res_all3[2][0][j],2),round(final_res_all3[3][0][j],2),round(final_res_all3[4][0][j],2))\n",
    "print('\\n\\n')\n",
    "\n",
    "for j in [1]:#range(3):\n",
    "    print('doc2vec ',emp[1],names[j],round(final_res_all2[0][1][j],2),round(final_res_all2[1][1][j],2),round(final_res_all2[2][1][j],2),round(final_res_all2[3][1][j],2),round(final_res_all2[4][1][j],2))    \n",
    "    print('tf-idf ',emp[1],names[j],round(final_res_all1[0][1][j],2),round(final_res_all1[1][1][j],2),round(final_res_all1[2][1][j],2),round(final_res_all1[3][1][j],2),round(final_res_all1[4][1][j],2))\n",
    "    print('lda    ',emp[1],names[j],round(final_res_all3[0][1][j],2),round(final_res_all3[1][1][j],2),round(final_res_all3[2][1][j],2),round(final_res_all3[3][1][j],2),round(final_res_all3[4][1][j],2))\n",
    "print('\\n\\n')\n",
    "for j in [1]:#range(3):\n",
    "    print('doc2vec ',emp[2],names[j],round(final_res_all2[0][2][j],2),round(final_res_all2[1][2][j],2),round(final_res_all2[2][2][j],2),round(final_res_all2[3][2][j],2),round(final_res_all2[4][2][j],2))\n",
    "    print('tf-idf ',emp[2],names[j],round(final_res_all1[0][2][j],2),round(final_res_all1[1][2][j],2),round(final_res_all1[2][2][j],2),round(final_res_all1[3][2][j],2),round(final_res_all1[4][2][j],2))\n",
    "    print('lda   ',emp[2],names[j],round(final_res_all3[0][2][j],2),round(final_res_all3[1][2][j],2),round(final_res_all3[2][2][j],2),round(final_res_all3[3][2][j],2),round(final_res_all3[4][2][j],2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top tf-idf based jaccard similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess1(corp):\n",
    "    corp1 = []\n",
    "    for art in corp:\n",
    "        art = art.lower()\n",
    "        art = art.replace('.',' ')\n",
    "        tokens = art.split(' ')\n",
    "        ext = []\n",
    "        for t in tokens:\n",
    "            t = t.replace(' ','')\n",
    "            ext.append(t)\n",
    "        corp1.append(' '.join(ext))\n",
    "    return corp1\n",
    "\n",
    "def get_top_tfidf(corp1,corp2):\n",
    "    corp1=preprocess1(corp1)\n",
    "    corp2=preprocess1(corp2)\n",
    "    vectorizer1 = TfidfVectorizer()\n",
    "    X1 = vectorizer1.fit_transform(corp1)\n",
    "    feature_array1 = np.array(vectorizer1.get_feature_names())\n",
    "    tfidf_sorting1 = np.argsort(X1.toarray()).flatten()[::-1]\n",
    "    vectorizer2 = TfidfVectorizer()\n",
    "    X2 = vectorizer2.fit_transform(corp2)\n",
    "    feature_array2 = np.array(vectorizer2.get_feature_names())\n",
    "    tfidf_sorting2 = np.argsort(X2.toarray()).flatten()[::-1]\n",
    "    words = [feature_array1[tfidf_sorting1][:100],feature_array2[tfidf_sorting2][:100]]\n",
    "    return words\n",
    "\n",
    "def jaccard_similar(voc_agri,voc_nagri):\n",
    "  intersect = set(voc_agri)&set(voc_nagri)\n",
    "  union = set(voc_agri).union(set(voc_nagri))\n",
    "  jaccard_similarity = round(float(len(intersect))/len(union),2)\n",
    "  return jaccard_similarity\n",
    "\n",
    "all_res = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collection: Agriculture\n",
      "\n",
      "Collection: Development\n",
      "\n",
      "Collection: Environment\n",
      "\n",
      "Collection: Industrialization\n",
      "\n",
      "Collection: Lifestyle\n",
      " Label               Agri  Dev  Env  Ind  Life \n",
      " Unemp  Slow vs Average 0.13 0.14 0.11 0.11 0.11\n",
      " Unemp  Slow vs Fast 0.12 0.13 0.14 0.14 0.12\n",
      " Unemp  Average vs Fast 0.11 0.12 0.13 0.11 0.11\n",
      " Agri   Slow vs Average 0.14 0.14 0.13 0.13 0.11\n",
      " Agri   Slow vs Fast 0.15 0.14 0.12 0.13 0.12\n",
      " Agri   Average vs Fast 0.15 0.14 0.14 0.13 0.11\n",
      "NonAgri Slow vs Average 0.12 0.14 0.13 0.11 0.12\n",
      "NonAgri Slow vs Fast 0.12 0.13 0.12 0.12 0.13\n",
      "NonAgri Average vs Fast 0.11 0.12 0.13 0.11 0.12\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "datasets = ['dataset_agriculture', 'dataset_development', 'dataset_environment', 'dataset_industrialization', 'dataset_lifestyle']\n",
    "model_names = ['model_agriculture', 'model_development', 'model_environment', 'model_industrialization', 'model_lifestyle']\n",
    "final_res_all = []\n",
    "for dataset, model in zip(datasets,model_names):\n",
    "    dataset_name = dataset\n",
    "    # Printing the collection name.\n",
    "    collection_name = dataset[8:]\n",
    "    print('\\nCollection:',collection_name.capitalize())\n",
    "    # Loading the dataset and the model from the drive.\n",
    "    file = open('Datasets/'+dataset, 'rb')\n",
    "    dataset = pickle.loads(zlib.decompress(pickle.load(file)))\n",
    "    file.close()\n",
    "    model = Doc2Vec.load('Models/'+model)\n",
    "    # Collecting the article_ids, and corresponding article_vectors for each class.\n",
    "    temp_ids = [set() for _ in range(9)]\n",
    "    temp_vectors = [[] for _ in range(9)]\n",
    "    temp_datasets = [[] for _ in range(9)]\n",
    "    temp_titles = [[] for _ in range(9)]\n",
    "    for i in dataset:\n",
    "        if i[6]=='Unemp' and i[-1]=='Slow':\n",
    "            if i[0] not in temp_ids[0]:\n",
    "                temp_ids[0].add(i[0])\n",
    "                temp_titles[0].append(i[1])\n",
    "                temp_vectors[0].append(i[2])\n",
    "                temp_datasets[0].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Unemp' and i[-1]=='Average':\n",
    "            if i[0] not in temp_ids[1]:\n",
    "                temp_ids[1].add(i[0])\n",
    "                temp_titles[1].append(i[1])\n",
    "                temp_vectors[1].append(i[2])\n",
    "                temp_datasets[1].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Unemp' and i[-1]=='Fast':\n",
    "            if i[0] not in temp_ids[2]:\n",
    "                temp_ids[2].add(i[0])\n",
    "                temp_titles[2].append(i[1])\n",
    "                temp_vectors[2].append(i[2])\n",
    "                temp_datasets[2].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Agri' and i[-1]=='Slow':\n",
    "            if i[0] not in temp_ids[3]:\n",
    "                temp_ids[3].add(i[0])\n",
    "                temp_titles[3].append(i[1])\n",
    "                temp_vectors[3].append(i[2])\n",
    "                temp_datasets[3].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Agri' and i[-1]=='Average':\n",
    "            if i[0] not in temp_ids[4]:\n",
    "                temp_ids[4].add(i[0])\n",
    "                temp_titles[4].append(i[1])\n",
    "                temp_vectors[4].append(i[2])\n",
    "                temp_datasets[4].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Agri' and i[-1]=='Fast':\n",
    "            if i[0] not in temp_ids[5]:\n",
    "                temp_ids[5].add(i[0])\n",
    "                temp_titles[5].append(i[1])\n",
    "                temp_vectors[5].append(i[2])\n",
    "                temp_datasets[5].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Non Agri' and i[-1]=='Slow':\n",
    "            if i[0] not in temp_ids[6]:\n",
    "                temp_ids[6].add(i[0])\n",
    "                temp_titles[6].append(i[1])\n",
    "                temp_vectors[6].append(i[2])\n",
    "                temp_datasets[6].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Non Agri' and i[-1]=='Average':\n",
    "            if i[0] not in temp_ids[7]:\n",
    "                temp_ids[7].add(i[0])\n",
    "                temp_titles[7].append(i[1])\n",
    "                temp_vectors[7].append(i[2])\n",
    "                temp_datasets[7].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Non Agri' and i[-1]=='Fast':\n",
    "            if i[0] not in temp_ids[8]:\n",
    "                temp_ids[8].add(i[0])\n",
    "                temp_titles[8].append(i[1])\n",
    "                temp_vectors[8].append(i[2])\n",
    "                temp_datasets[8].append([i[0],model.docvecs[i[0]]])\n",
    "    names = ['unemp_avg_id','unemp_slow_id','unemp_fast_id','agri_avg_id','agri_slow_id','agri_fast_id','non_agri_avg_id','non_agri_slow_id','non_agri_fast_id']\n",
    "    df = pd.read_excel('RS/'+collection_name+'_ids.xlsx')\n",
    "    all_val = []\n",
    "    for i in [0,3,6]:\n",
    "        voc1 = (read_indice(list(df[names[i]]),temp_titles[i],temp_ids[i]))\n",
    "        voc2 = (read_indice(list(df[names[i+1]]),temp_titles[i+1],temp_ids[i+1]))\n",
    "        voc3 = (read_indice(list(df[names[i+2]]),temp_titles[i+2],temp_ids[i+2]))\n",
    "        words1 = get_top_tfidf(voc1,voc2)\n",
    "        words2 = get_top_tfidf(voc3,voc2)\n",
    "        words3 = get_top_tfidf(voc1,voc3)\n",
    "        lst = [jaccard_similar(words1[0],words1[1]),jaccard_similar(words2[0],words2[1]),jaccard_similar(words3[0],words3[1])]\n",
    "        all_val.append(lst)\n",
    "    final_res_all.append(all_val)\n",
    "all_res.append(final_res_all)\n",
    "names = [\"Slow vs Average\",\"Slow vs Fast\",\"Average vs Fast\"]\n",
    "emp = [\" Unemp \",\" Agri  \",\"NonAgri\"]\n",
    "print(\" Label              \",\"Agri \",\"Dev \",\"Env \",\"Ind \",\"Life \")\n",
    "for j in range(3):\n",
    "    print(emp[0],names[j],round(final_res_all[0][0][j],2),round(final_res_all[1][0][j],2),round(final_res_all[2][0][j],2),round(final_res_all[3][0][j],2),round(final_res_all[4][0][j],2))\n",
    "\n",
    "for j in range(3):\n",
    "    print(emp[1],names[j],round(final_res_all[0][1][j],2),round(final_res_all[1][1][j],2),round(final_res_all[2][1][j],2),round(final_res_all[3][1][j],2),round(final_res_all[4][1][j],2))\n",
    "\n",
    "for j in range(3):\n",
    "    print(emp[2],names[j],round(final_res_all[0][2][j],2),round(final_res_all[1][2][j],2),round(final_res_all[2][2][j],2),round(final_res_all[3][2][j],2),round(final_res_all[4][2][j],2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collection: Agriculture\n",
      "\n",
      "Collection: Development\n",
      "\n",
      "Collection: Environment\n",
      "\n",
      "Collection: Industrialization\n",
      "\n",
      "Collection: Lifestyle\n",
      " Label               Agri  Dev  Env  Ind  Life \n",
      " Unemp  Slow vs Average 0.13 0.13 0.13 0.13 0.11\n",
      " Unemp  Slow vs Fast 0.12 0.13 0.13 0.12 0.11\n",
      " Unemp  Average vs Fast 0.14 0.14 0.14 0.12 0.12\n",
      " Agri   Slow vs Average 0.15 0.16 0.13 0.12 0.11\n",
      " Agri   Slow vs Fast 0.14 0.15 0.12 0.11 0.14\n",
      " Agri   Average vs Fast 0.14 0.16 0.13 0.11 0.13\n",
      "NonAgri Slow vs Average 0.12 0.12 0.11 0.12 0.12\n",
      "NonAgri Slow vs Fast 0.13 0.13 0.13 0.13 0.11\n",
      "NonAgri Average vs Fast 0.14 0.1 0.13 0.1 0.11\n"
     ]
    }
   ],
   "source": [
    "#####For DocTag2Vec\n",
    "\n",
    "import pandas as pd\n",
    "datasets = ['dataset_agriculture', 'dataset_development', 'dataset_environment', 'dataset_industrialization', 'dataset_lifestyle']\n",
    "model_names = ['model_agriculture', 'model_development', 'model_environment', 'model_industrialization', 'model_lifestyle']\n",
    "final_res_all = []\n",
    "for dataset, model in zip(datasets,model_names):\n",
    "    dataset_name = dataset\n",
    "    # Printing the collection name.\n",
    "    collection_name = dataset[8:]\n",
    "    print('\\nCollection:',collection_name.capitalize())\n",
    "    # Loading the dataset and the model from the drive.\n",
    "    file = open('Datasets/'+dataset, 'rb')\n",
    "    dataset = pickle.loads(zlib.decompress(pickle.load(file)))\n",
    "    file.close()\n",
    "    model = Doc2Vec.load('Models/'+model)\n",
    "\n",
    "    # Collecting the article_ids, and corresponding article_vectors for each class.\n",
    "    temp_ids = [set() for _ in range(9)]\n",
    "    temp_vectors = [[] for _ in range(9)]\n",
    "    temp_datasets = [[] for _ in range(9)]\n",
    "    temp_titles = [[] for _ in range(9)]\n",
    "    for i in dataset:\n",
    "        if i[6]=='Unemp' and i[-1]=='Slow':\n",
    "            if i[0] not in temp_ids[0]:\n",
    "                temp_ids[0].add(i[0])\n",
    "                temp_titles[0].append(i[1])\n",
    "                temp_vectors[0].append(i[2])\n",
    "                temp_datasets[0].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Unemp' and i[-1]=='Average':\n",
    "            if i[0] not in temp_ids[1]:\n",
    "                temp_ids[1].add(i[0])\n",
    "                temp_titles[1].append(i[1])\n",
    "                temp_vectors[1].append(i[2])\n",
    "                temp_datasets[1].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Unemp' and i[-1]=='Fast':\n",
    "            if i[0] not in temp_ids[2]:\n",
    "                temp_ids[2].add(i[0])\n",
    "                temp_titles[2].append(i[1])\n",
    "                temp_vectors[2].append(i[2])\n",
    "                temp_datasets[2].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Agri' and i[-1]=='Slow':\n",
    "            if i[0] not in temp_ids[3]:\n",
    "                temp_ids[3].add(i[0])\n",
    "                temp_titles[3].append(i[1])\n",
    "                temp_vectors[3].append(i[2])\n",
    "                temp_datasets[3].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Agri' and i[-1]=='Average':\n",
    "            if i[0] not in temp_ids[4]:\n",
    "                temp_ids[4].add(i[0])\n",
    "                temp_titles[4].append(i[1])\n",
    "                temp_vectors[4].append(i[2])\n",
    "                temp_datasets[4].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Agri' and i[-1]=='Fast':\n",
    "            if i[0] not in temp_ids[5]:\n",
    "                temp_ids[5].add(i[0])\n",
    "                temp_titles[5].append(i[1])\n",
    "                temp_vectors[5].append(i[2])\n",
    "                temp_datasets[5].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Non Agri' and i[-1]=='Slow':\n",
    "            if i[0] not in temp_ids[6]:\n",
    "                temp_ids[6].add(i[0])\n",
    "                temp_titles[6].append(i[1])\n",
    "                temp_vectors[6].append(i[2])\n",
    "                temp_datasets[6].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Non Agri' and i[-1]=='Average':\n",
    "            if i[0] not in temp_ids[7]:\n",
    "                temp_ids[7].add(i[0])\n",
    "                temp_titles[7].append(i[1])\n",
    "                temp_vectors[7].append(i[2])\n",
    "                temp_datasets[7].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Non Agri' and i[-1]=='Fast':\n",
    "            if i[0] not in temp_ids[8]:\n",
    "                temp_ids[8].add(i[0])\n",
    "                temp_titles[8].append(i[1])\n",
    "                temp_vectors[8].append(i[2])\n",
    "                temp_datasets[8].append([i[0],model.docvecs[i[0]]])\n",
    "    names = ['unemp_avg_id','unemp_slow_id','unemp_fast_id','agri_avg_id','agri_slow_id','agri_fast_id','non_agri_avg_id','non_agri_slow_id','non_agri_fast_id']\n",
    "    df = pd.read_excel('DocTag2Vec/'+collection_name+'_ids.xlsx')\n",
    "    all_val = []\n",
    "    for i in [0,3,6]:    \n",
    "        voc1 = (read_indice(list(df[names[i]]),temp_titles[i],temp_ids[i]))\n",
    "        voc2 = (read_indice(list(df[names[i+1]]),temp_titles[i+1],temp_ids[i+1]))\n",
    "        voc3 = (read_indice(list(df[names[i+2]]),temp_titles[i+2],temp_ids[i+2]))\n",
    "        words1 = get_top_tfidf(voc1,voc2)\n",
    "        words2 = get_top_tfidf(voc3,voc2)\n",
    "        words3 = get_top_tfidf(voc1,voc3)\n",
    "        lst = [jaccard_similar(words1[0],words1[1]),jaccard_similar(words2[0],words2[1]),jaccard_similar(words3[0],words3[1])]\n",
    "        all_val.append(lst)\n",
    "        \n",
    "    final_res_all.append(all_val)\n",
    "all_res.append(final_res_all)\n",
    "names = [\"Slow vs Average\",\"Slow vs Fast\",\"Average vs Fast\"]\n",
    "emp = [\" Unemp \",\" Agri  \",\"NonAgri\"]\n",
    "print(\" Label              \",\"Agri \",\"Dev \",\"Env \",\"Ind \",\"Life \")\n",
    "for j in range(3):\n",
    "    print(emp[0],names[j],round(final_res_all[0][0][j],2),round(final_res_all[1][0][j],2),round(final_res_all[2][0][j],2),round(final_res_all[3][0][j],2),round(final_res_all[4][0][j],2))\n",
    "\n",
    "for j in range(3):\n",
    "    print(emp[1],names[j],round(final_res_all[0][1][j],2),round(final_res_all[1][1][j],2),round(final_res_all[2][1][j],2),round(final_res_all[3][1][j],2),round(final_res_all[4][1][j],2))\n",
    "\n",
    "for j in range(3):\n",
    "    print(emp[2],names[j],round(final_res_all[0][2][j],2),round(final_res_all[1][2][j],2),round(final_res_all[2][2][j],2),round(final_res_all[3][2][j],2),round(final_res_all[4][2][j],2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collection: Agriculture\n",
      "\n",
      "Collection: Development\n",
      "\n",
      "Collection: Environment\n",
      "\n",
      "Collection: Industrialization\n",
      "\n",
      "Collection: Lifestyle\n",
      " Label               Agri  Dev  Env  Ind  Life \n",
      " Unemp  Slow vs Average 0.12 0.13 0.12 0.1 0.12\n",
      " Unemp  Slow vs Fast 0.14 0.12 0.13 0.14 0.12\n",
      " Unemp  Average vs Fast 0.11 0.14 0.13 0.11 0.11\n",
      " Agri   Slow vs Average 0.15 0.15 0.13 0.12 0.12\n",
      " Agri   Slow vs Fast 0.15 0.15 0.13 0.11 0.12\n",
      " Agri   Average vs Fast 0.14 0.18 0.14 0.13 0.12\n",
      "NonAgri Slow vs Average 0.13 0.12 0.13 0.11 0.12\n",
      "NonAgri Slow vs Fast 0.12 0.13 0.14 0.09 0.12\n",
      "NonAgri Average vs Fast 0.12 0.13 0.12 0.1 0.11\n"
     ]
    }
   ],
   "source": [
    "#####For LDA\n",
    "\n",
    "import pandas as pd\n",
    "datasets = ['dataset_agriculture', 'dataset_development', 'dataset_environment', 'dataset_industrialization', 'dataset_lifestyle']\n",
    "model_names = ['model_agriculture', 'model_development', 'model_environment', 'model_industrialization', 'model_lifestyle']\n",
    "final_res_all = []\n",
    "for dataset, model in zip(datasets,model_names):\n",
    "    dataset_name = dataset\n",
    "    # Printing the collection name.\n",
    "    collection_name = dataset[8:]\n",
    "    print('\\nCollection:',collection_name.capitalize())\n",
    "    # Loading the dataset and the model from the drive.\n",
    "    file = open('Datasets/'+dataset, 'rb')\n",
    "    dataset = pickle.loads(zlib.decompress(pickle.load(file)))\n",
    "    file.close()\n",
    "    model = Doc2Vec.load('Models/'+model)\n",
    "\n",
    "    # Collecting the article_ids, and corresponding article_vectors for each class.\n",
    "    temp_ids = [set() for _ in range(9)]\n",
    "    temp_vectors = [[] for _ in range(9)]\n",
    "    temp_datasets = [[] for _ in range(9)]\n",
    "    temp_titles = [[] for _ in range(9)]\n",
    "    for i in dataset:\n",
    "        if i[6]=='Unemp' and i[-1]=='Slow':\n",
    "            if i[0] not in temp_ids[0]:\n",
    "                temp_ids[0].add(i[0])\n",
    "                temp_titles[0].append(i[1])\n",
    "                temp_vectors[0].append(i[2])\n",
    "                temp_datasets[0].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Unemp' and i[-1]=='Average':\n",
    "            if i[0] not in temp_ids[1]:\n",
    "                temp_ids[1].add(i[0])\n",
    "                temp_titles[1].append(i[1])\n",
    "                temp_vectors[1].append(i[2])\n",
    "                temp_datasets[1].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Unemp' and i[-1]=='Fast':\n",
    "            if i[0] not in temp_ids[2]:\n",
    "                temp_ids[2].add(i[0])\n",
    "                temp_titles[2].append(i[1])\n",
    "                temp_vectors[2].append(i[2])\n",
    "                temp_datasets[2].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Agri' and i[-1]=='Slow':\n",
    "            if i[0] not in temp_ids[3]:\n",
    "                temp_ids[3].add(i[0])\n",
    "                temp_titles[3].append(i[1])\n",
    "                temp_vectors[3].append(i[2])\n",
    "                temp_datasets[3].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Agri' and i[-1]=='Average':\n",
    "            if i[0] not in temp_ids[4]:\n",
    "                temp_ids[4].add(i[0])\n",
    "                temp_titles[4].append(i[1])\n",
    "                temp_vectors[4].append(i[2])\n",
    "                temp_datasets[4].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Agri' and i[-1]=='Fast':\n",
    "            if i[0] not in temp_ids[5]:\n",
    "                temp_ids[5].add(i[0])\n",
    "                temp_titles[5].append(i[1])\n",
    "                temp_vectors[5].append(i[2])\n",
    "                temp_datasets[5].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Non Agri' and i[-1]=='Slow':\n",
    "            if i[0] not in temp_ids[6]:\n",
    "                temp_ids[6].add(i[0])\n",
    "                temp_titles[6].append(i[1])\n",
    "                temp_vectors[6].append(i[2])\n",
    "                temp_datasets[6].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Non Agri' and i[-1]=='Average':\n",
    "            if i[0] not in temp_ids[7]:\n",
    "                temp_ids[7].add(i[0])\n",
    "                temp_titles[7].append(i[1])\n",
    "                temp_vectors[7].append(i[2])\n",
    "                temp_datasets[7].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Non Agri' and i[-1]=='Fast':\n",
    "            if i[0] not in temp_ids[8]:\n",
    "                temp_ids[8].add(i[0])\n",
    "                temp_titles[8].append(i[1])\n",
    "                temp_vectors[8].append(i[2])\n",
    "                temp_datasets[8].append([i[0],model.docvecs[i[0]]])\n",
    "    names = ['unemp_avg_id','unemp_slow_id','unemp_fast_id','agri_avg_id','agri_slow_id','agri_fast_id','non_agri_avg_id','non_agri_slow_id','non_agri_fast_id']\n",
    "    df = pd.read_excel('LDA/'+collection_name+'_ids.xlsx')\n",
    "    all_val = []\n",
    "    for i in [0,3,6]:\n",
    "        voc1 = (read_indice(list(df[names[i]]),temp_titles[i],temp_ids[i]))\n",
    "        voc2 = (read_indice(list(df[names[i+1]]),temp_titles[i+1],temp_ids[i+1]))\n",
    "        voc3 = (read_indice(list(df[names[i+2]]),temp_titles[i+2],temp_ids[i+2]))\n",
    "        \n",
    "        words1 = get_top_tfidf(voc1,voc2)\n",
    "        words2 = get_top_tfidf(voc3,voc2)\n",
    "        words3 = get_top_tfidf(voc1,voc3)\n",
    "        lst = [jaccard_similar(words1[0],words1[1]),jaccard_similar(words2[0],words2[1]),jaccard_similar(words3[0],words3[1])]\n",
    "        all_val.append(lst)\n",
    "    final_res_all.append(all_val)\n",
    "all_res.append(final_res_all)\n",
    "names = [\"Slow vs Average\",\"Slow vs Fast\",\"Average vs Fast\"]\n",
    "emp = [\" Unemp \",\" Agri  \",\"NonAgri\"]\n",
    "print(\" Label              \",\"Agri \",\"Dev \",\"Env \",\"Ind \",\"Life \")\n",
    "for j in range(3):\n",
    "    print(emp[0],names[j],round(final_res_all[0][0][j],2),round(final_res_all[1][0][j],2),round(final_res_all[2][0][j],2),round(final_res_all[3][0][j],2),round(final_res_all[4][0][j],2))\n",
    "\n",
    "for j in range(3):\n",
    "    print(emp[1],names[j],round(final_res_all[0][1][j],2),round(final_res_all[1][1][j],2),round(final_res_all[2][1][j],2),round(final_res_all[3][1][j],2),round(final_res_all[4][1][j],2))\n",
    "\n",
    "for j in range(3):\n",
    "    print(emp[2],names[j],round(final_res_all[0][2][j],2),round(final_res_all[1][2][j],2),round(final_res_all[2][2][j],2),round(final_res_all[3][2][j],2),round(final_res_all[4][2][j],2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Label               Agri  Dev  Env  Ind  Life \n",
      "doc2vec   Unemp  Slow vs Fast 0.12 0.13 0.13 0.12 0.11\n",
      "tf-idf   Unemp  Slow vs Fast 0.12 0.13 0.14 0.14 0.12\n",
      "lda      Unemp  Slow vs Fast 0.14 0.12 0.13 0.14 0.12\n",
      "\n",
      "\n",
      "\n",
      "doc2vec   Agri   Slow vs Fast 0.14 0.15 0.12 0.11 0.14\n",
      "tf-idf   Agri   Slow vs Fast 0.15 0.14 0.12 0.13 0.12\n",
      "lda      Agri   Slow vs Fast 0.15 0.15 0.13 0.11 0.12\n",
      "\n",
      "\n",
      "\n",
      "doc2vec  NonAgri Slow vs Fast 0.13 0.13 0.13 0.13 0.11\n",
      "tf-idf  NonAgri Slow vs Fast 0.12 0.13 0.12 0.12 0.13\n",
      "lda    NonAgri Slow vs Fast 0.12 0.13 0.14 0.09 0.12\n"
     ]
    }
   ],
   "source": [
    "names = [\"Slow vs Average\",\"Slow vs Fast\",\"Average vs Fast\"]\n",
    "emp = [\" Unemp \",\" Agri  \",\"NonAgri\"]\n",
    "\n",
    "print(\" Label              \",\"Agri \",\"Dev \",\"Env \",\"Ind \",\"Life \")\n",
    "final_res_all1 = all_res[0]\n",
    "final_res_all2 = all_res[1]\n",
    "final_res_all3 = all_res[2]\n",
    "\n",
    "for j in [1]:#range(3):\n",
    "    print('doc2vec ',emp[0],names[j],round(final_res_all2[0][0][j],2),round(final_res_all2[1][0][j],2),round(final_res_all2[2][0][j],2),round(final_res_all2[3][0][j],2),round(final_res_all2[4][0][j],2))\n",
    "    print('tf-idf ',emp[0],names[j],round(final_res_all1[0][0][j],2),round(final_res_all1[1][0][j],2),round(final_res_all1[2][0][j],2),round(final_res_all1[3][0][j],2),round(final_res_all1[4][0][j],2))\n",
    "    print('lda    ',emp[0],names[j],round(final_res_all3[0][0][j],2),round(final_res_all3[1][0][j],2),round(final_res_all3[2][0][j],2),round(final_res_all3[3][0][j],2),round(final_res_all3[4][0][j],2))\n",
    "print('\\n\\n')\n",
    "\n",
    "for j in [1]:#range(3):\n",
    "    print('doc2vec ',emp[1],names[j],round(final_res_all2[0][1][j],2),round(final_res_all2[1][1][j],2),round(final_res_all2[2][1][j],2),round(final_res_all2[3][1][j],2),round(final_res_all2[4][1][j],2))    \n",
    "    print('tf-idf ',emp[1],names[j],round(final_res_all1[0][1][j],2),round(final_res_all1[1][1][j],2),round(final_res_all1[2][1][j],2),round(final_res_all1[3][1][j],2),round(final_res_all1[4][1][j],2))\n",
    "    print('lda    ',emp[1],names[j],round(final_res_all3[0][1][j],2),round(final_res_all3[1][1][j],2),round(final_res_all3[2][1][j],2),round(final_res_all3[3][1][j],2),round(final_res_all3[4][1][j],2))\n",
    "print('\\n\\n')\n",
    "for j in [1]:#range(3):\n",
    "    print('doc2vec ',emp[2],names[j],round(final_res_all2[0][2][j],2),round(final_res_all2[1][2][j],2),round(final_res_all2[2][2][j],2),round(final_res_all2[3][2][j],2),round(final_res_all2[4][2][j],2))\n",
    "    print('tf-idf ',emp[2],names[j],round(final_res_all1[0][2][j],2),round(final_res_all1[1][2][j],2),round(final_res_all1[2][2][j],2),round(final_res_all1[3][2][j],2),round(final_res_all1[4][2][j],2))\n",
    "    print('lda   ',emp[2],names[j],round(final_res_all3[0][2][j],2),round(final_res_all3[1][2][j],2),round(final_res_all3[2][2][j],2),round(final_res_all3[3][2][j],2),round(final_res_all3[4][2][j],2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from scipy.stats import entropy\n",
    "import math\n",
    "from collections import Counter\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess1(corp):\n",
    "    corp1 = []\n",
    "    for art in corp:\n",
    "        art = art.lower()\n",
    "        tokens = tokenizer.tokenize(art)\n",
    "        ext = []\n",
    "        for t in tokens:\n",
    "            if t not in stop_words:\n",
    "                ext.append(t)\n",
    "        corp1.append(' '.join(ext))\n",
    "    return corp1\n",
    "\n",
    "def get_top_tfidf(corp1,corp2):\n",
    "    corp1=preprocess1(corp1)\n",
    "    corp2=preprocess1(corp2)\n",
    "    vectorizer1 = TfidfVectorizer()\n",
    "    X1 = vectorizer1.fit_transform(corp1)\n",
    "    feature_array1 = np.array(vectorizer1.get_feature_names())\n",
    "    tfidf_sorting1 = np.argsort(X1.toarray()).flatten()[::-1]\n",
    "    vectorizer2 = TfidfVectorizer()\n",
    "    X2 = vectorizer2.fit_transform(corp2)\n",
    "    feature_array2 = np.array(vectorizer2.get_feature_names())\n",
    "    tfidf_sorting2 = np.argsort(X2.toarray()).flatten()[::-1]\n",
    "    words = [feature_array1[tfidf_sorting1][:100],feature_array2[tfidf_sorting2][:100]]\n",
    "    cp1 = {}\n",
    "    cp2 = {}\n",
    "    crp1 = []\n",
    "    for i in corp1:\n",
    "        crp1 += i.split(' ')\n",
    "    crp2=[]\n",
    "    for i in corp2:\n",
    "        crp2 += i.split(' ')\n",
    "    cnt1= Counter(crp1)\n",
    "    cnt2 = Counter(crp2)\n",
    "    for i in words[0]:\n",
    "        cp1[i] = cnt1[i]\n",
    "    for i in words[1]:\n",
    "        cp2[i] = cnt2[i]\n",
    "    words = [cp1,cp2]\n",
    "    return words\n",
    "\n",
    "def jaccard_similar(voc_agri,voc_nagri):\n",
    "  #jaccard on vocab\n",
    "  \n",
    "  intersect = set(voc_agri)&set(voc_nagri)\n",
    "  union = set(voc_agri).union(set(voc_nagri))\n",
    "  jaccard_similarity = len(intersect)/len(union)\n",
    "  return jaccard_similarity\n",
    "\n",
    "\n",
    "def cal_entropy(voc_agri,voc_nagri):\n",
    "  p1 = []\n",
    "  p2 = []\n",
    "  bst=[]\n",
    "  intersect = set(voc_agri)&set(voc_nagri)\n",
    "  for i in intersect:\n",
    "    if voc_agri[i]==0 and voc_nagri[i]==0:\n",
    "        continue   \n",
    "    p1.append(voc_agri[i]/(voc_agri[i]+voc_nagri[i]))\n",
    "    p2.append(voc_nagri[i]/(voc_agri[i]+voc_nagri[i]))\n",
    "    bst.append(max(p1[-1],p2[-1]))\n",
    "  ent = 0\n",
    "  for p in bst:\n",
    "        ent = ent - p*math.log(p)\n",
    "  return entropy(bst,base=2)\n",
    "\n",
    "all_res = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collection: Agriculture\n",
      "\n",
      "Collection: Development\n",
      "\n",
      "Collection: Environment\n",
      "\n",
      "Collection: Industrialization\n",
      "\n",
      "Collection: Lifestyle\n",
      " Label               Agri  Dev  Env  Ind  Life \n",
      " Unemp  Slow vs Average 8.72 8.64 8.28 8.59 8.46\n",
      " Unemp  Slow vs Fast 8.6 8.6 8.43 8.26 8.65\n",
      " Unemp  Average vs Fast 8.67 8.63 8.52 8.41 8.37\n",
      " Agri   Slow vs Average 8.6 8.68 8.47 8.5 8.55\n",
      " Agri   Slow vs Fast 8.32 8.74 8.57 8.61 8.27\n",
      " Agri   Average vs Fast 8.31 8.67 8.4 8.51 8.25\n",
      "NonAgri Slow vs Average 8.6 8.67 8.69 8.34 8.49\n",
      "NonAgri Slow vs Fast 8.46 8.68 8.59 8.63 8.59\n",
      "NonAgri Average vs Fast 8.48 8.76 8.62 8.34 8.53\n"
     ]
    }
   ],
   "source": [
    "#####For DocTag2Vec\n",
    "\n",
    "import pandas as pd\n",
    "datasets = ['dataset_agriculture', 'dataset_development', 'dataset_environment', 'dataset_industrialization', 'dataset_lifestyle']\n",
    "model_names = ['model_agriculture', 'model_development', 'model_environment', 'model_industrialization', 'model_lifestyle']\n",
    "final_res_all = []\n",
    "for dataset, model in zip(datasets,model_names):\n",
    "    dataset_name = dataset\n",
    "    # Printing the collection name.\n",
    "    collection_name = dataset[8:]\n",
    "    print('\\nCollection:',collection_name.capitalize())\n",
    "    # Loading the dataset and the model from the drive.\n",
    "    file = open('Datasets/'+dataset, 'rb')\n",
    "    dataset = pickle.loads(zlib.decompress(pickle.load(file)))\n",
    "    file.close()\n",
    "    model = Doc2Vec.load('Models/'+model)\n",
    "\n",
    "    # Collecting the article_ids, and corresponding article_vectors for each class.\n",
    "    temp_ids = [set() for _ in range(9)]\n",
    "    temp_vectors = [[] for _ in range(9)]\n",
    "    temp_datasets = [[] for _ in range(9)]\n",
    "    temp_titles = [[] for _ in range(9)]\n",
    "    for i in dataset:\n",
    "        if i[6]=='Unemp' and i[-1]=='Slow':\n",
    "            if i[0] not in temp_ids[0]:\n",
    "                temp_ids[0].add(i[0])\n",
    "                temp_titles[0].append(i[1])\n",
    "                temp_vectors[0].append(i[2])\n",
    "                temp_datasets[0].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Unemp' and i[-1]=='Average':\n",
    "            if i[0] not in temp_ids[1]:\n",
    "                temp_ids[1].add(i[0])\n",
    "                temp_titles[1].append(i[1])\n",
    "                temp_vectors[1].append(i[2])\n",
    "                temp_datasets[1].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Unemp' and i[-1]=='Fast':\n",
    "            if i[0] not in temp_ids[2]:\n",
    "                temp_ids[2].add(i[0])\n",
    "                temp_titles[2].append(i[1])\n",
    "                temp_vectors[2].append(i[2])\n",
    "                temp_datasets[2].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Agri' and i[-1]=='Slow':\n",
    "            if i[0] not in temp_ids[3]:\n",
    "                temp_ids[3].add(i[0])\n",
    "                temp_titles[3].append(i[1])\n",
    "                temp_vectors[3].append(i[2])\n",
    "                temp_datasets[3].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Agri' and i[-1]=='Average':\n",
    "            if i[0] not in temp_ids[4]:\n",
    "                temp_ids[4].add(i[0])\n",
    "                temp_titles[4].append(i[1])\n",
    "                temp_vectors[4].append(i[2])\n",
    "                temp_datasets[4].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Agri' and i[-1]=='Fast':\n",
    "            if i[0] not in temp_ids[5]:\n",
    "                temp_ids[5].add(i[0])\n",
    "                temp_titles[5].append(i[1])\n",
    "                temp_vectors[5].append(i[2])\n",
    "                temp_datasets[5].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Non Agri' and i[-1]=='Slow':\n",
    "            if i[0] not in temp_ids[6]:\n",
    "                temp_ids[6].add(i[0])\n",
    "                temp_titles[6].append(i[1])\n",
    "                temp_vectors[6].append(i[2])\n",
    "                temp_datasets[6].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Non Agri' and i[-1]=='Average':\n",
    "            if i[0] not in temp_ids[7]:\n",
    "                temp_ids[7].add(i[0])\n",
    "                temp_titles[7].append(i[1])\n",
    "                temp_vectors[7].append(i[2])\n",
    "                temp_datasets[7].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Non Agri' and i[-1]=='Fast':\n",
    "            if i[0] not in temp_ids[8]:\n",
    "                temp_ids[8].add(i[0])\n",
    "                temp_titles[8].append(i[1])\n",
    "                temp_vectors[8].append(i[2])\n",
    "                temp_datasets[8].append([i[0],model.docvecs[i[0]]])\n",
    "    names = ['unemp_avg_id','unemp_slow_id','unemp_fast_id','agri_avg_id','agri_slow_id','agri_fast_id','non_agri_avg_id','non_agri_slow_id','non_agri_fast_id']\n",
    "    df = pd.read_excel('DocTag2Vec/'+collection_name+'_ids.xlsx')\n",
    "    all_val = []\n",
    "    for i in [0,3,6]:\n",
    "        voc1 = (read_indice(list(df[names[i]]),temp_vectors[i],temp_ids[i]))\n",
    "        voc2 = (read_indice(list(df[names[i+1]]),temp_vectors[i+1],temp_ids[i+1]))\n",
    "        voc3 = (read_indice(list(df[names[i+2]]),temp_vectors[i+2],temp_ids[i+2]))\n",
    "        words1 = get_top_tfidf(voc1,voc2)\n",
    "        words2 = get_top_tfidf(voc3,voc2)\n",
    "        words3 = get_top_tfidf(voc1,voc3)\n",
    "        lst = [cal_entropy((words1[0]),(words1[1])),cal_entropy((words2[0]),(words2[1])),\n",
    "               cal_entropy((words3[0]),(words3[1]))]\n",
    "        all_val.append(lst)\n",
    "\n",
    "    final_res_all.append(all_val)\n",
    "all_res.append(final_res_all)\n",
    "names = [\"Slow vs Average\",\"Slow vs Fast\",\"Average vs Fast\"]\n",
    "emp = [\" Unemp \",\" Agri  \",\"NonAgri\"]\n",
    "print(\" Label              \",\"Agri \",\"Dev \",\"Env \",\"Ind \",\"Life \")\n",
    "for j in range(3):\n",
    "    print(emp[0],names[j],round(final_res_all[0][0][j],2),round(final_res_all[1][0][j],2),round(final_res_all[2][0][j],2),round(final_res_all[3][0][j],2),round(final_res_all[4][0][j],2))\n",
    "\n",
    "for j in range(3):\n",
    "    print(emp[1],names[j],round(final_res_all[0][1][j],2),round(final_res_all[1][1][j],2),round(final_res_all[2][1][j],2),round(final_res_all[3][1][j],2),round(final_res_all[4][1][j],2))\n",
    "\n",
    "for j in range(3):\n",
    "    print(emp[2],names[j],round(final_res_all[0][2][j],2),round(final_res_all[1][2][j],2),round(final_res_all[2][2][j],2),round(final_res_all[3][2][j],2),round(final_res_all[4][2][j],2))\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collection: Agriculture\n",
      "\n",
      "Collection: Development\n",
      "\n",
      "Collection: Environment\n",
      "\n",
      "Collection: Industrialization\n",
      "\n",
      "Collection: Lifestyle\n",
      " Label               Agri  Dev  Env  Ind  Life \n",
      " Unemp  Slow vs Average 8.63 8.59 8.47 8.66 8.58\n",
      " Unemp  Slow vs Fast 8.46 8.7 8.41 8.2 8.61\n",
      " Unemp  Average vs Fast 8.47 8.5 8.59 8.2 8.57\n",
      " Agri   Slow vs Average 8.55 8.66 8.57 8.67 8.44\n",
      " Agri   Slow vs Fast 8.47 8.52 8.5 8.71 8.6\n",
      " Agri   Average vs Fast 8.27 8.49 8.46 8.62 8.44\n",
      "NonAgri Slow vs Average 8.51 8.74 8.64 8.76 8.63\n",
      "NonAgri Slow vs Fast 8.68 8.73 8.62 8.57 8.62\n",
      "NonAgri Average vs Fast 8.57 8.62 8.57 8.48 8.5\n"
     ]
    }
   ],
   "source": [
    "#tfidf\n",
    "import pandas as pd\n",
    "datasets = ['dataset_agriculture', 'dataset_development', 'dataset_environment', 'dataset_industrialization', 'dataset_lifestyle']\n",
    "model_names = ['model_agriculture', 'model_development', 'model_environment', 'model_industrialization', 'model_lifestyle']\n",
    "final_res_all = []\n",
    "for dataset, model in zip(datasets,model_names):\n",
    "    dataset_name = dataset\n",
    "    # Printing the collection name.\n",
    "    collection_name = dataset[8:]\n",
    "    print('\\nCollection:',collection_name.capitalize())\n",
    "    # Loading the dataset and the model from the drive.\n",
    "    file = open('Datasets/'+dataset, 'rb')\n",
    "    dataset = pickle.loads(zlib.decompress(pickle.load(file)))\n",
    "    file.close()\n",
    "    model = Doc2Vec.load('Models/'+model)\n",
    "\n",
    "    # Collecting the article_ids, and corresponding article_vectors for each class.\n",
    "    temp_ids = [set() for _ in range(9)]\n",
    "    temp_vectors = [[] for _ in range(9)]\n",
    "    temp_datasets = [[] for _ in range(9)]\n",
    "    temp_titles = [[] for _ in range(9)]\n",
    "    for i in dataset:\n",
    "        if i[6]=='Unemp' and i[-1]=='Slow':\n",
    "            if i[0] not in temp_ids[0]:\n",
    "                temp_ids[0].add(i[0])\n",
    "                temp_titles[0].append(i[1])\n",
    "                temp_vectors[0].append(i[2])\n",
    "                temp_datasets[0].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Unemp' and i[-1]=='Average':\n",
    "            if i[0] not in temp_ids[1]:\n",
    "                temp_ids[1].add(i[0])\n",
    "                temp_titles[1].append(i[1])\n",
    "                temp_vectors[1].append(i[2])\n",
    "                temp_datasets[1].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Unemp' and i[-1]=='Fast':\n",
    "            if i[0] not in temp_ids[2]:\n",
    "                temp_ids[2].add(i[0])\n",
    "                temp_titles[2].append(i[1])\n",
    "                temp_vectors[2].append(i[2])\n",
    "                temp_datasets[2].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Agri' and i[-1]=='Slow':\n",
    "            if i[0] not in temp_ids[3]:\n",
    "                temp_ids[3].add(i[0])\n",
    "                temp_titles[3].append(i[1])\n",
    "                temp_vectors[3].append(i[2])\n",
    "                temp_datasets[3].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Agri' and i[-1]=='Average':\n",
    "            if i[0] not in temp_ids[4]:\n",
    "                temp_ids[4].add(i[0])\n",
    "                temp_titles[4].append(i[1])\n",
    "                temp_vectors[4].append(i[2])\n",
    "                temp_datasets[4].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Agri' and i[-1]=='Fast':\n",
    "            if i[0] not in temp_ids[5]:\n",
    "                temp_ids[5].add(i[0])\n",
    "                temp_titles[5].append(i[1])\n",
    "                temp_vectors[5].append(i[2])\n",
    "                temp_datasets[5].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Non Agri' and i[-1]=='Slow':\n",
    "            if i[0] not in temp_ids[6]:\n",
    "                temp_ids[6].add(i[0])\n",
    "                temp_titles[6].append(i[1])\n",
    "                temp_vectors[6].append(i[2])\n",
    "                temp_datasets[6].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Non Agri' and i[-1]=='Average':\n",
    "            if i[0] not in temp_ids[7]:\n",
    "                temp_ids[7].add(i[0])\n",
    "                temp_titles[7].append(i[1])\n",
    "                temp_vectors[7].append(i[2])\n",
    "                temp_datasets[7].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Non Agri' and i[-1]=='Fast':\n",
    "            if i[0] not in temp_ids[8]:\n",
    "                temp_ids[8].add(i[0])\n",
    "                temp_titles[8].append(i[1])\n",
    "                temp_vectors[8].append(i[2])\n",
    "                temp_datasets[8].append([i[0],model.docvecs[i[0]]])\n",
    "    names = ['unemp_avg_id','unemp_slow_id','unemp_fast_id','agri_avg_id','agri_slow_id','agri_fast_id','non_agri_avg_id','non_agri_slow_id','non_agri_fast_id']\n",
    "    df = pd.read_excel('RS/'+collection_name+'_ids.xlsx')\n",
    "    all_val = []\n",
    "    for i in [0,3,6]:\n",
    "        voc1 = (read_indice(list(df[names[i]]),temp_vectors[i],temp_ids[i]))\n",
    "        voc2 = (read_indice(list(df[names[i+1]]),temp_vectors[i+1],temp_ids[i+1]))\n",
    "        voc3 = (read_indice(list(df[names[i+2]]),temp_vectors[i+2],temp_ids[i+2]))\n",
    "        words1 = get_top_tfidf(voc1,voc2)\n",
    "        words2 = get_top_tfidf(voc3,voc2)\n",
    "        words3 = get_top_tfidf(voc1,voc3)\n",
    "        lst = [cal_entropy((words1[0]),(words1[1])),cal_entropy((words2[0]),(words2[1])),\n",
    "               cal_entropy((words3[0]),(words3[1]))]\n",
    "        all_val.append(lst)\n",
    "    final_res_all.append(all_val)\n",
    "all_res.append(final_res_all)\n",
    "names = [\"Slow vs Average\",\"Slow vs Fast\",\"Average vs Fast\"]\n",
    "emp = [\" Unemp \",\" Agri  \",\"NonAgri\"]\n",
    "print(\" Label              \",\"Agri \",\"Dev \",\"Env \",\"Ind \",\"Life \")\n",
    "for j in range(3):\n",
    "    print(emp[0],names[j],round(final_res_all[0][0][j],2),round(final_res_all[1][0][j],2),round(final_res_all[2][0][j],2),round(final_res_all[3][0][j],2),round(final_res_all[4][0][j],2))\n",
    "\n",
    "for j in range(3):\n",
    "    print(emp[1],names[j],round(final_res_all[0][1][j],2),round(final_res_all[1][1][j],2),round(final_res_all[2][1][j],2),round(final_res_all[3][1][j],2),round(final_res_all[4][1][j],2))\n",
    "\n",
    "for j in range(3):\n",
    "    print(emp[2],names[j],round(final_res_all[0][2][j],2),round(final_res_all[1][2][j],2),round(final_res_all[2][2][j],2),round(final_res_all[3][2][j],2),round(final_res_all[4][2][j],2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collection: Agriculture\n",
      "\n",
      "Collection: Development\n",
      "\n",
      "Collection: Environment\n",
      "\n",
      "Collection: Industrialization\n",
      "\n",
      "Collection: Lifestyle\n",
      " Label               Agri  Dev  Env  Ind  Life \n",
      " Unemp  Slow vs Average 8.65 8.65 8.37 8.53 8.39\n",
      " Unemp  Slow vs Fast 8.69 8.71 8.49 8.54 8.58\n",
      " Unemp  Average vs Fast 8.73 8.62 8.45 8.6 8.4\n",
      " Agri   Slow vs Average 8.45 8.58 8.63 8.47 8.35\n",
      " Agri   Slow vs Fast 8.33 8.56 8.43 8.67 8.49\n",
      " Agri   Average vs Fast 8.55 8.62 8.61 8.41 8.59\n",
      "NonAgri Slow vs Average 8.57 8.67 8.32 8.69 8.33\n",
      "NonAgri Slow vs Fast 8.59 8.6 8.28 8.39 8.66\n",
      "NonAgri Average vs Fast 8.57 8.54 8.04 8.45 8.31\n"
     ]
    }
   ],
   "source": [
    "#####For LDA\n",
    "\n",
    "import pandas as pd\n",
    "datasets = ['dataset_agriculture', 'dataset_development', 'dataset_environment', 'dataset_industrialization', 'dataset_lifestyle']\n",
    "model_names = ['model_agriculture', 'model_development', 'model_environment', 'model_industrialization', 'model_lifestyle']\n",
    "final_res_all = []\n",
    "for dataset, model in zip(datasets,model_names):\n",
    "    dataset_name = dataset\n",
    "    # Printing the collection name.\n",
    "    collection_name = dataset[8:]\n",
    "    print('\\nCollection:',collection_name.capitalize())\n",
    "    # Loading the dataset and the model from the drive.\n",
    "    file = open('Datasets/'+dataset, 'rb')\n",
    "    dataset = pickle.loads(zlib.decompress(pickle.load(file)))\n",
    "    file.close()\n",
    "    model = Doc2Vec.load('Models/'+model)\n",
    "\n",
    "    # Collecting the article_ids, and corresponding article_vectors for each class.\n",
    "    temp_ids = [set() for _ in range(9)]\n",
    "    temp_vectors = [[] for _ in range(9)]\n",
    "    temp_datasets = [[] for _ in range(9)]\n",
    "    temp_titles = [[] for _ in range(9)]\n",
    "    for i in dataset:\n",
    "        if i[6]=='Unemp' and i[-1]=='Slow':\n",
    "            if i[0] not in temp_ids[0]:\n",
    "                temp_ids[0].add(i[0])\n",
    "                temp_titles[0].append(i[1])\n",
    "                temp_vectors[0].append(i[2])\n",
    "                temp_datasets[0].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Unemp' and i[-1]=='Average':\n",
    "            if i[0] not in temp_ids[1]:\n",
    "                temp_ids[1].add(i[0])\n",
    "                temp_titles[1].append(i[1])\n",
    "                temp_vectors[1].append(i[2])\n",
    "                temp_datasets[1].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Unemp' and i[-1]=='Fast':\n",
    "            if i[0] not in temp_ids[2]:\n",
    "                temp_ids[2].add(i[0])\n",
    "                temp_titles[2].append(i[1])\n",
    "                temp_vectors[2].append(i[2])\n",
    "                temp_datasets[2].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Agri' and i[-1]=='Slow':\n",
    "            if i[0] not in temp_ids[3]:\n",
    "                temp_ids[3].add(i[0])\n",
    "                temp_titles[3].append(i[1])\n",
    "                temp_vectors[3].append(i[2])\n",
    "                temp_datasets[3].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Agri' and i[-1]=='Average':\n",
    "            if i[0] not in temp_ids[4]:\n",
    "                temp_ids[4].add(i[0])\n",
    "                temp_titles[4].append(i[1])\n",
    "                temp_vectors[4].append(i[2])\n",
    "                temp_datasets[4].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Agri' and i[-1]=='Fast':\n",
    "            if i[0] not in temp_ids[5]:\n",
    "                temp_ids[5].add(i[0])\n",
    "                temp_titles[5].append(i[1])\n",
    "                temp_vectors[5].append(i[2])\n",
    "                temp_datasets[5].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Non Agri' and i[-1]=='Slow':\n",
    "            if i[0] not in temp_ids[6]:\n",
    "                temp_ids[6].add(i[0])\n",
    "                temp_titles[6].append(i[1])\n",
    "                temp_vectors[6].append(i[2])\n",
    "                temp_datasets[6].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Non Agri' and i[-1]=='Average':\n",
    "            if i[0] not in temp_ids[7]:\n",
    "                temp_ids[7].add(i[0])\n",
    "                temp_titles[7].append(i[1])\n",
    "                temp_vectors[7].append(i[2])\n",
    "                temp_datasets[7].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[6]=='Non Agri' and i[-1]=='Fast':\n",
    "            if i[0] not in temp_ids[8]:\n",
    "                temp_ids[8].add(i[0])\n",
    "                temp_titles[8].append(i[1])\n",
    "                temp_vectors[8].append(i[2])\n",
    "                temp_datasets[8].append([i[0],model.docvecs[i[0]]])\n",
    "    names = ['unemp_avg_id','unemp_slow_id','unemp_fast_id','agri_avg_id','agri_slow_id','agri_fast_id','non_agri_avg_id','non_agri_slow_id','non_agri_fast_id']\n",
    "    df = pd.read_excel('LDA/'+collection_name+'_ids.xlsx')\n",
    "    all_val = []\n",
    "    for i in [0,3,6]:\n",
    "        voc1 = (read_indice(list(df[names[i]]),temp_vectors[i],temp_ids[i]))\n",
    "        voc2 = (read_indice(list(df[names[i+1]]),temp_vectors[i+1],temp_ids[i+1]))\n",
    "        voc3 = (read_indice(list(df[names[i+2]]),temp_vectors[i+2],temp_ids[i+2]))\n",
    "        words1 = get_top_tfidf(voc1,voc2)\n",
    "        words2 = get_top_tfidf(voc3,voc2)\n",
    "        words3 = get_top_tfidf(voc1,voc3)\n",
    "        lst = [cal_entropy((words1[0]),(words1[1])),cal_entropy((words2[0]),(words2[1])),\n",
    "               cal_entropy((words3[0]),(words3[1]))]\n",
    "        all_val.append(lst)\n",
    "    final_res_all.append(all_val)\n",
    "all_res.append(final_res_all)\n",
    "names = [\"Slow vs Average\",\"Slow vs Fast\",\"Average vs Fast\"]\n",
    "emp = [\" Unemp \",\" Agri  \",\"NonAgri\"]\n",
    "print(\" Label              \",\"Agri \",\"Dev \",\"Env \",\"Ind \",\"Life \")\n",
    "for j in range(3):\n",
    "    print(emp[0],names[j],round(final_res_all[0][0][j],2),round(final_res_all[1][0][j],2),round(final_res_all[2][0][j],2),round(final_res_all[3][0][j],2),round(final_res_all[4][0][j],2))\n",
    "\n",
    "for j in range(3):\n",
    "    print(emp[1],names[j],round(final_res_all[0][1][j],2),round(final_res_all[1][1][j],2),round(final_res_all[2][1][j],2),round(final_res_all[3][1][j],2),round(final_res_all[4][1][j],2))\n",
    "\n",
    "for j in range(3):\n",
    "    print(emp[2],names[j],round(final_res_all[0][2][j],2),round(final_res_all[1][2][j],2),round(final_res_all[2][2][j],2),round(final_res_all[3][2][j],2),round(final_res_all[4][2][j],2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Label               Agri  Dev  Env  Ind  Life \n",
      "doc2vec   Unemp  Slow vs Fast 5.96 5.96 5.84 5.73 6.0\n",
      "tf-idf   Unemp  Slow vs Fast 5.57 6.08 5.77 5.94 5.69\n",
      "lda      Unemp  Slow vs Fast 6.02 6.03 5.89 5.92 5.95\n",
      "\n",
      "\n",
      "\n",
      "doc2vec   Agri   Slow vs Fast 5.77 6.06 5.94 5.97 5.73\n",
      "tf-idf   Agri   Slow vs Fast 5.8 5.78 5.84 4.73 5.96\n",
      "lda      Agri   Slow vs Fast 5.78 5.93 5.84 6.01 5.88\n",
      "\n",
      "\n",
      "\n",
      "doc2vec  NonAgri Slow vs Fast 5.86 6.01 5.95 5.98 5.95\n",
      "tf-idf  NonAgri Slow vs Fast 5.91 5.98 5.99 5.87 5.92\n",
      "lda    NonAgri Slow vs Fast 5.96 5.96 5.74 5.82 6.0\n"
     ]
    }
   ],
   "source": [
    "names = [\"Slow vs Average\",\"Slow vs Fast\",\"Average vs Fast\"]\n",
    "emp = [\" Unemp \",\" Agri  \",\"NonAgri\"]\n",
    "\n",
    "print(\" Label              \",\"Agri \",\"Dev \",\"Env \",\"Ind \",\"Life \")\n",
    "final_res_all1 = all_res[-3]\n",
    "final_res_all2 = all_res[-2]\n",
    "final_res_all3 = all_res[-1]\n",
    "\n",
    "for j in [1]:#range(3):\n",
    "    print('doc2vec ',emp[0],names[j],round(final_res_all1[0][0][j],2),round(final_res_all1[1][0][j],2),round(final_res_all1[2][0][j],2),round(final_res_all1[3][0][j],2),round(final_res_all1[4][0][j],2))\n",
    "    print('tf-idf ',emp[0],names[j],round(final_res_all2[0][0][j],2),round(final_res_all2[1][0][j],2),round(final_res_all2[2][0][j],2),round(final_res_all2[3][0][j],2),round(final_res_all2[4][0][j],2))\n",
    "    print('lda    ',emp[0],names[j],round(final_res_all3[0][0][j],2),round(final_res_all3[1][0][j],2),round(final_res_all3[2][0][j],2),round(final_res_all3[3][0][j],2),round(final_res_all3[4][0][j],2))\n",
    "print('\\n\\n')\n",
    "\n",
    "for j in [1]:#range(3):\n",
    "    print('doc2vec ',emp[1],names[j],round(final_res_all1[0][1][j],2),round(final_res_all1[1][1][j],2),round(final_res_all1[2][1][j],2),round(final_res_all1[3][1][j],2),round(final_res_all1[4][1][j],2))\n",
    "    print('tf-idf ',emp[1],names[j],round(final_res_all2[0][1][j],2),round(final_res_all2[1][1][j],2),round(final_res_all2[2][1][j],2),round(final_res_all2[3][1][j],2),round(final_res_all2[4][1][j],2))    \n",
    "    print('lda    ',emp[1],names[j],round(final_res_all3[0][1][j],2),round(final_res_all3[1][1][j],2),round(final_res_all3[2][1][j],2),round(final_res_all3[3][1][j],2),round(final_res_all3[4][1][j],2))\n",
    "print('\\n\\n')\n",
    "for j in [1]:#range(3):\n",
    "    print('doc2vec ',emp[2],names[j],round(final_res_all1[0][2][j],2),round(final_res_all1[1][2][j],2),round(final_res_all1[2][2][j],2),round(final_res_all1[3][2][j],2),round(final_res_all1[4][2][j],2))\n",
    "    print('tf-idf ',emp[2],names[j],round(final_res_all2[0][2][j],2),round(final_res_all2[1][2][j],2),round(final_res_all2[2][2][j],2),round(final_res_all2[3][2][j],2),round(final_res_all2[4][2][j],2))\n",
    "    print('lda   ',emp[2],names[j],round(final_res_all3[0][2][j],2),round(final_res_all3[1][2][j],2),round(final_res_all3[2][2][j],2),round(final_res_all3[3][2][j],2),round(final_res_all3[4][2][j],2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
