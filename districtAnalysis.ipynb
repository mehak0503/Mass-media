{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle, zlib\n",
    "from random import sample\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans \n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import single, fcluster\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy.cluster.hierarchy import single, cophenet\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from collections import Counter\n",
    "import sys\n",
    "import math\n",
    "sys.setrecursionlimit(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downsampling\n",
    "def sampling(data):\n",
    "    limit = 10000\n",
    "    ind = []\n",
    "    if len(data)>limit:\n",
    "        ind = sample([i for i in range(len(data))],limit)\n",
    "        data = [data[i] for i in ind]\n",
    "    else:\n",
    "        ind = [i for i in range(len(data))]\n",
    "    return data,ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fancy_dendrogram(*args, **kwargs):\n",
    "    max_d = kwargs.pop('max_d', None)\n",
    "    if max_d and 'color_threshold' not in kwargs:\n",
    "        kwargs['color_threshold'] = max_d\n",
    "    annotate_above = kwargs.pop('annotate_above', 0)\n",
    "\n",
    "    ddata = dendrogram(*args, **kwargs)\n",
    "\n",
    "    if not kwargs.get('no_plot', False):\n",
    "        plt.title('Hierarchical Clustering Dendrogram (truncated)')\n",
    "        plt.xlabel('sample index or (cluster size)')\n",
    "        plt.ylabel('distance')\n",
    "        for i, d, c in zip(ddata['icoord'], ddata['dcoord'], ddata['color_list']):\n",
    "            x = 0.5 * sum(i[1:3])\n",
    "            y = d[1]\n",
    "            if y > annotate_above:\n",
    "                plt.plot(x, y, 'o', c=c)\n",
    "                plt.annotate(\"%.3g\" % y, (x, y), xytext=(0, -5),\n",
    "                             textcoords='offset points',\n",
    "                             va='top', ha='center')\n",
    "        if max_d:\n",
    "            plt.axhline(y=max_d, c='k')\n",
    "    return ddata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose method and metric\n",
    "def choose_metric(data):\n",
    "    method = ['single','complete','average','weighted','centroid','ward']\n",
    "    metric = ['euclidean','cosine']\n",
    "    maxx = None\n",
    "    use_method = None\n",
    "    use_metric = None\n",
    "    '''for m1 in method:\n",
    "        for m2 in metric:\n",
    "            try:\n",
    "                linkage_matrix = sch.linkage(data, m1, metric=m2)\n",
    "                c, coph_dists = cophenet(linkage_matrix, pdist(data))\n",
    "                print(\"Method=\",m1,\" Metric=\",m2,\" Cophenet coeff=\",c)\n",
    "                plot_dendro(linkage_matrix)\n",
    "                if maxx is None or c>maxx:\n",
    "                    maxx = c\n",
    "                    use_method = m1\n",
    "                    use_metric = m2\n",
    "                print(m1,m2,c)\n",
    "            except Exception as e:\n",
    "                print(e)'''\n",
    "    use_method ='ward' #input('Input the suitable method: ')\n",
    "    use_metric = 'euclidean' #input('Input the suitable metric: ')\n",
    "    return use_method,use_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot dendrograms and we are interested in huge jump in distance \n",
    "def plot_dendro(linkage_matrix):\n",
    "    for threshold in np.arange(10,110,10):\n",
    "        labels = sch.fcluster(linkage_matrix, threshold, criterion='distance')\n",
    "        fancy_dendrogram(\n",
    "            linkage_matrix,\n",
    "            truncate_mode='lastp',\n",
    "            p=30,\n",
    "            leaf_rotation=90.,\n",
    "            leaf_font_size=12.,\n",
    "            show_contracted=True,\n",
    "            annotate_above=10,  # useful in small plots so annotations don't overlap\n",
    "            max_d=threshold\n",
    "            )\n",
    "        plt.show()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminate outlier clusters\n",
    "def eliminate_outlier(data,linkage_matrix,method,metric,thresh=50):\n",
    "    labels = sch.fcluster(linkage_matrix, thresh, criterion='distance')\n",
    "    d = Counter(labels)\n",
    "    sorted_d = sorted(d.items(), key = lambda kv:(kv[1], kv[0])) \n",
    "    maxx = None\n",
    "    art_thresh = None\n",
    "    '''val = 1\n",
    "    ind = 0\n",
    "    flag = False\n",
    "    while maxx is None or flag:\n",
    "        flag = False\n",
    "        val = sorted_d[ind][1]\n",
    "        clusters = [i for i,j in sorted_d if j==val]\n",
    "        ind = sorted_d.index((clusters[-1],val))+1\n",
    "        indices = []\n",
    "        for c in clusters:\n",
    "            indices = indices+[i for i, x in enumerate(labels) if x == c]\n",
    "        revised_data = [data[i] for i in range(len(data)) if i not in indices]\n",
    "        linkage_matrix = sch.linkage(revised_data, method, metric=metric)\n",
    "        c, coph_dists = cophenet(linkage_matrix, pdist(revised_data))\n",
    "        print(val,c)\n",
    "        if maxx is None or c>maxx:\n",
    "            maxx = c\n",
    "            flag = True\n",
    "    return val\n",
    "    '''\n",
    "    itm = list(d.values())\n",
    "    for art in range(1,101):\n",
    "        if art not in itm:\n",
    "            continue\n",
    "        clusters = []\n",
    "        for i,j in sorted_d:\n",
    "            if j<art:\n",
    "                clusters.append(i)\n",
    "        indices = []\n",
    "        for c in clusters:\n",
    "            indices = indices+[i for i, x in enumerate(labels) if x == c]\n",
    "        revised_data = [data[i] for i in range(len(data)) if i not in indices]\n",
    "        print(len(revised_data),len(indices),len(data))\n",
    "        linkage_matrix = sch.linkage(revised_data, method, metric=metric)\n",
    "        c, coph_dists = cophenet(linkage_matrix, pdist(revised_data))\n",
    "        \n",
    "        if maxx is None or c>=maxx:\n",
    "            maxx = c\n",
    "            art_thresh = art\n",
    "    print(art_thresh,c,maxx)\n",
    "    return art_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute rank\n",
    "def compute_scr(linkage_matrix,data,art_thresh,thresh=50):\n",
    "    labels = sch.fcluster(linkage_matrix, thresh, criterion='distance')\n",
    "    d = Counter(labels)\n",
    "    sorted_d = sorted(d.items(), key = lambda kv:(kv[1], kv[0])) \n",
    "    clusters = []\n",
    "    for i,j in sorted_d:\n",
    "        if j<=art_thresh:\n",
    "            clusters.append(i)\n",
    "    indices = []\n",
    "    for c in clusters:\n",
    "        indices = indices+[i for i, x in enumerate(labels) if x == c]\n",
    "    ind = [i for i in range(len(data)) if i not in indices]\n",
    "    revised_data = [data[i] for i in ind]\n",
    "    labels=list(labels)\n",
    "    labels = [labels[i] for i in ind]\n",
    "    print(len(ind),len(revised_data),len(data))\n",
    "    if len(set(labels))==1:\n",
    "        centroids = [np.mean(revised_data,axis=0)]\n",
    "    else:\n",
    "        clf = NearestCentroid()\n",
    "        clf.fit(revised_data, labels) \n",
    "        centroids = clf.centroids_\n",
    "    print(len(ind),len(revised_data),len(data),len(centroids))\n",
    "    num1 = [i for i in range(len(set(labels)))]\n",
    "    num2 = sorted(set(labels))\n",
    "    for i in range(len(num1)):\n",
    "        labels=[num1[i] if x==num2[i] else x for x in labels]\n",
    "    ranks = []\n",
    "    for i in range(len(labels)):\n",
    "        ranks.append((cosine_similarity(centroids[labels[i]].reshape(1,-1),revised_data[i].reshape(1,-1))[0][0]+1)/2) #cos_sim(row1, row2)- minx)/(maxx-minx)\n",
    "    return revised_data,labels,centroids,ranks,ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#driver function\n",
    "def driver_func(data1):\n",
    "    data,indx = sampling(data1)\n",
    "    method,metric= choose_metric(data)\n",
    "    linkage_matrix = sch.linkage(data, method, metric=metric)\n",
    "    plot_dendro(linkage_matrix)\n",
    "    #thresh = 50\n",
    "    thresh = 100#input('Input distance threshold value based on dendrogram: ')\n",
    "    art_thresh = 0#eliminate_outlier(data,linkage_matrix,method,metric,thresh)\n",
    "    return indx,compute_scr(linkage_matrix,data,art_thresh,thresh)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#global centroid\n",
    "def global_centroid(data):\n",
    "    return np.median(np.array(data),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rank B,C\n",
    "def get_rank(data,global_centroid):\n",
    "    ranks = []\n",
    "    for d in data:\n",
    "        ranks.append((cosine_similarity(global_centroid.reshape(1,-1),d.reshape(1,-1))[0][0]+1)/2) #cos_sim(row1, row2)- minx)/(maxx-minx)\n",
    "    return ranks\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get filtered\n",
    "def get_filtered(data,indx,indA,art):\n",
    "    data_= [data[a] for a in range(len(data)) if a in indx]\n",
    "    data_= [data_[a] for a in range(len(data_)) if a in indA]\n",
    "    data_ = [data_[a] for a in art]\n",
    "    return data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get pattern result\n",
    "def get_pat_res(data1,data2):\n",
    "    indx1,out1= driver_func(data1)\n",
    "    (revised_data1,labels1,centroids1,rankA1,indA1) = out1\n",
    "    indx2,out2= driver_func(data2)\n",
    "    (revised_data2,labels2,centroids2,rankA2,indA2) = out2\n",
    "    gc1 = global_centroid(revised_data1)\n",
    "    gc2 = global_centroid(revised_data2)\n",
    "    rankB1 = get_rank(revised_data1, gc1)\n",
    "    rankB2 = get_rank(revised_data2, gc2)\n",
    "    rankC1 = get_rank(revised_data1, gc2)\n",
    "    rankC2 = get_rank(revised_data2, gc1)\n",
    "    scores1=[]\n",
    "    for i,j,k in zip(rankA1,rankB1,rankC1):\n",
    "        scores1.append(i*j-k)\n",
    "    scores2=[]\n",
    "    for i,j,k in zip(rankA2,rankB2,rankC2):\n",
    "        scores2.append(i*j-k)\n",
    "    cluster1 = {}\n",
    "    for i in range(len(labels1)):\n",
    "        if labels1[i] in cluster1.keys():\n",
    "            cluster1[labels1[i]][0].append(i)\n",
    "            cluster1[labels1[i]][1].append(scores1[i])\n",
    "        else:\n",
    "            cluster1[labels1[i]] = [[i],[scores1[i]]]\n",
    "    cluster2 = {}\n",
    "    for i in range(len(labels2)):\n",
    "        if labels2[i] in cluster2.keys():\n",
    "            cluster2[labels2[i]][0].append(i)\n",
    "            cluster2[labels2[i]][1].append(scores2[i])\n",
    "        else:\n",
    "            cluster2[labels2[i]] = [[i],[scores2[i]]]\n",
    "    num1=int(100/len(centroids1))+1\n",
    "    articles1 = []\n",
    "    for c in cluster1:\n",
    "        sort_ind = np.argsort(np.array(cluster1[c][1]))\n",
    "        indx = [cluster1[c][0][i] for i in sort_ind[-num1:]]\n",
    "        articles1+=indx\n",
    "    \n",
    "    num2=int(100/len(centroids2))+1\n",
    "    articles2 = []\n",
    "    for c in cluster2:\n",
    "        sort_ind = np.argsort(np.array(cluster2[c][1]))\n",
    "        indx = [cluster2[c][0][i] for i in sort_ind[-num2:]]\n",
    "        articles2+=indx\n",
    "    return sample(articles1,min(len(articles1),100)),sample(articles2,min(len(articles2),100)),indA1,indA2,indx1,indx2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collection: Agriculture\n",
      "agriculture0\n",
      "Number of articles: 378 \tNumber of clusters: 11\n",
      "Will monsoon turn saviour of samba?\n",
      "Monsoon may be good but kuruvai prospects bleak\n",
      "Grand Anicut to be opened today\n",
      "Samba paddy cultivation picking up in Tiruvarur\n",
      "Distressed over crop failure, another farmer in Tiruvarur dies\n",
      "A dim Deepavali for delta farmers\n",
      "Coconut growers seek remunerative support price\n",
      "‘Use green manure for sustainable agriculture’\n",
      "Heavy rain in Tiruvarur and Thanjavur\n",
      "Intermittent showers drench central districts\n",
      "Govt assures compensation for entire crop damage\n",
      "Government caps coconut farmers’ relief, ‘clarifies’ after uproar\n",
      "Delta districts get a respite from rain\n",
      "Paddy inundated on large tracts of land\n",
      "Over 5K held in delta as Cauvery stir spills on to streets\n",
      "Central region gets seven berths in the Cabinet\n",
      "CPI to launch rail rokos in delta districts on October 9\n",
      "Delta farmer commits suicide\n",
      "Crop failure claims five lives in the delta\n",
      "Two farmers in Madurai, Tuticorin commit suicide over crop loss\n",
      "\n",
      "\n",
      "\n",
      "agriculture1\n",
      "Number of articles: 548 \tNumber of clusters: 12\n",
      "Rain brightens samba prospects in delta\n",
      "Harvest in 1,000 hectares of pumpset irrigated areas over\n",
      "Farmers despair at samba prospects\n",
      "Monsoon may be good but kuruvai prospects bleak\n",
      "“Ensure kuruvai package reaches ryots”\n",
      "Rs. 9.19 cr. for Kuruvai package in Thanjavur\n",
      "AIADMK condemns petrol price hike\n",
      "Mixed response to strike call\n",
      "Farmers want 100% interest waiver\n",
      "Farmers want 100% waiver, after Cabinet okays 60-day interest waiver in light of demonetisation\n",
      "Heavy rain lashes delta districts\n",
      "Heavy rain in Tiruvarur and Thanjavur\n",
      "In Tamil Nadu, when cows aren’t always for keeping\n",
      "When cows aren’t for keeping\n",
      "Festival demand pushes flower prices up\n",
      "TN vendors make beeline for Chittoor markets for vegetables\n",
      "NABARD launches campaign on water conservation\n",
      "Periyar TBI takes expertise in areca leaf plate-making to Andaman\n",
      "Nammalvar moots own panel to expose methane project in delta\n",
      "Hydrocarbon issue haunts voters in Delta\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collection: Development\n",
      "development0\n",
      "Number of articles: 34 \tNumber of clusters: 11\n",
      "Gram sabha meetings on Oct 2\n",
      "Social audit of PDS registers conducted at grama sabha meetings\n",
      "Rs. 32.89 crore for 5,160 farm ponds: Collector\n",
      "Kuruvai crop on 26,000 hectares in Tiruvarur\n",
      "Weed removal works taken up\n",
      "Weed removal works taken up on Harischandranathi\n",
      "1 lakh concrete houses will be built for cyclone-hit: CM\n",
      "CM promises special scheme for restoration work in Gaja-hit areas\n",
      "Poultry farms to be set up in seven districts\n",
      "State to promote manufactured sand\n",
      "MGNREGS provides succour to cyclone-affected people\n",
      "In welfarist T.N., a gamechanger with glitches\n",
      "​MGNREGS workers available for private farms, but few takers for it\n",
      "Efforts of local youth raise the hope of a bumper crop in Tamil Nadu’s Cauvery delta\n",
      "Farmers protest demanding drought relief, arrested\n",
      "CPI cadre held for road roko\n",
      "Tangedco plans major upgrade\n",
      "Camp to weigh children\n",
      "‘Job reservation will continue till disparities exist in society’\n",
      "Albendazole tablets distributed to school students\n",
      "\n",
      "\n",
      "\n",
      "development1\n",
      "Number of articles: 78 \tNumber of clusters: 10\n",
      "“Declare delta as drought-hit’’\n",
      "14 check-dams to come up across Cauvery tributaries\n",
      "Gram sabha meetings on Oct 2\n",
      "Gram sabha on Tuesday\n",
      "Farmers protest demanding drought relief, arrested\n",
      "Samba transplantation over in targeted areas\n",
      "Collector: all support to budding entrepreneurs\n",
      "Support assured for new entrepreneurs\n",
      "Vital Cauvery-Veerachozhanaaru regulator motorised\n",
      "Poor amenities\n",
      "Rs. 250 crore allocated under job scheme\n",
      "Thanjavur gets Rs. 250 crore under employment scheme\n",
      "Tangedco plans major upgrade\n",
      "Delta region to get 22 substations\n",
      "Delta's cup of woes overflows, even Cauvery won't be of help\n",
      "Farmers of delta region disappointed\n",
      "Rs.2.8 crore-facelift for Grand Anicut park\n",
      "Rs.2.8 cr. facelift for Grand Anicut park\n",
      "SIPPO training\n",
      "Entrepreneurship training programme commences\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collection: Environment\n",
      "environment0\n",
      "Number of articles: 70 \tNumber of clusters: 10\n",
      "Training for the greening corps\n",
      "Women entrepreneurs plan to spread network\n",
      "Paddy area shrinking in delta districts, says study\n",
      "Paddy area shrinking in delta districts: study\n",
      "Delta farmers continue opposition to coal-bed methane project\n",
      "Oppn sponsored bandh against Tuticorin violence\n",
      "Vedanta gets approval for tests for 274 hydrocarbon wells in T.N., Puducherry\n",
      "Vedanta gets nod to conduct impact assessment for 274 hydrocarbon wells in T.N., Puducherry\n",
      "State to promote manufactured sand\n",
      "Textile park in Perambalur, SIDCO industrial complex in Ariyalur\n",
      "New Forest Circle to come up in Thanjavur\n",
      "Pachamalai hills becomes preferred weekend getaway\n",
      "Bar headed geese stop over in Vaduvur\n",
      "Birds from far and near arrive at Vaduvur\n",
      "Drive launched to rescue parakeets\n",
      "Cows fall to viral disease in Kumbakonam too\n",
      "Thyagaraja music festival begins today\n",
      "Thyagaraja aradhana at Thiruvaiyaru from today\n",
      "Sand boa seized; three arrested\n",
      "Gold haul at Trichy airport\n",
      "\n",
      "\n",
      "\n",
      "environment1\n",
      "Number of articles: 127 \tNumber of clusters: 12\n",
      "Jallikattu will be conducted smoothly: TN\n",
      "Jallikattu protests: What is the uproar in Tamil Nadu all about?\n",
      "Delta farmers continue opposition to coal-bed methane project\n",
      "Paddy area shrinking in delta districts: study\n",
      "Textiles give tourism a fillip in the state\n",
      "Ancient temples help TN top tourism chart\n",
      "Seven ministers from central region sworn in\n",
      "HC says no to quarrying on Kollidam riverbed\n",
      "Conservation agriculture technologies popularised\n",
      "‘Dugong scholarship’\n",
      "Chennai's day out amid tides and trash\n",
      "Hundreds participate in environmental awareness rally at Meenakshi temple\n",
      "EPS distributes green awards to officials, firms\n",
      "EPS makes a slew of announcements in House\n",
      "High Court refuses blanket nod for jallikattu across Tamil Nadu\n",
      "HC refuses blanket nod for jallikattu\n",
      "Soil samples analysis confirm fears of farmers in Delta region\n",
      "Kadiramangalam residents counter ONGC claims\n",
      "NHAI told to plant 20,000 saplings within two days\n",
      "NHAI told to plant 20,000 saplings within two days\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collection: Industrialization\n",
      "industrialization0\n",
      "Number of articles: 52 \tNumber of clusters: 10\n",
      "Potters want free access to clay\n",
      "As hopes of Kuruvai wither  farmers look to alternatives\n",
      "Samba crop on 2.51 lakh hectares\n",
      "Award to six panchayats\n",
      "State gears up to tackle monsoon fury\n",
      "Content of parking tickets\n",
      "New trains, lines cheer passengers\n",
      "Chemmozhi Express flagged off\n",
      "Voters confront candidates with methane issue\n",
      "Nammalvar moots own panel to expose methane project in delta\n",
      "`VGP Housing’ achieves tremendous growth\n",
      "Textile park in Perambalur, SIDCO industrial complex in Ariyalur\n",
      "Mobile medical units deployed in cyclone-hit dists\n",
      "Gaja Cyclone: Mobile medical units deployed in cyclone-hit districts\n",
      "NABARD envisages credit flow of Rs. 3,654 cr\n",
      "Rs. 4 250.22 crore credit potential for Tiruvarur district in 2019-20\n",
      "No city school among 25 in Tamil Nadu that swept swacch awards\n",
      "Being denied compensation, woman petitions collector\n",
      "Two arrested for data theft\n",
      "Fire engine knocks down 70-year-old\n",
      "\n",
      "\n",
      "\n",
      "industrialization1\n",
      "Number of articles: 123 \tNumber of clusters: 11\n",
      "State gears up to tackle monsoon fury\n",
      "Consignment of fertilizers for samba crop arrives\n",
      "Handloom expo in Kumbakonam\n",
      "Potters want free access to clay\n",
      "State committed to developing tourism\n",
      "Textiles give tourism a fillip in the state\n",
      "State restrained from quarrying river sand\n",
      "Bullock cart workers seek permission to transport sand\n",
      "Collector: all support to budding entrepreneurs\n",
      "BHELSIA mulls cluster model to increase output\n",
      "Scorned by society, devadasis shined as stars on celluloid\n",
      "Coimbatore’s amateur theatre, a forgotten legacy that awaits final act\n",
      "Villagers disrupt ONGC work in Kumbakonam\n",
      "Situation at Kathiramangalam village calm now: Tamil Nadu CM K Palaniswami\n",
      "Youth groups show the clean way\n",
      "Velankanni gears up for festival\n",
      "Rajagopalachariar to head Paundarikapuram Ashramam\n",
      "Poundarikapuram Jeer laid to rest\n",
      "Judge expresses concern over tough recovery of tractor loans\n",
      "Judge expresses concern over ‘tough action’ on farm loans\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collection: Lifestyle\n",
      "lifestyle0\n",
      "Number of articles: 157 \tNumber of clusters: 11\n",
      "Paddy area shrinking in delta districts, says study\n",
      "Paddy area shrinking in delta districts: study\n",
      "M K Stalin cites father’s initiatives to strike emotional chord with farmers\n",
      "Karunanidhi breaks his own record of victory margin\n",
      "Social audit of PDS registers conducted at grama sabha meetings\n",
      "Inter-school contest\n",
      "PIL questions shifting of ancient idols to ‘icon centres’\n",
      "Srirangam soaks in religious fervour\n",
      "Two men held for cheating job aspirants of Rs. 85 lakh\n",
      "Two men held for cheating job aspirants of Rs. 85 lakh\n",
      "Screening for haemoglobin and anaemia control\n",
      "Albendazole tablets distributed to school students\n",
      "Tamil Nadu grapples with brain fever\n",
      "Tamil Nadu grapples with brain fever\n",
      "Special trains to Velankanni\n",
      "Special trains to clear rush for Velankanni Feast\n",
      "2 children brutally killed, mother critical\n",
      "Woman arrested for killing granny in Porur\n",
      "Report on milk adulteration finds 11 samples unsafe\n",
      "Training on detecting adulteration\n",
      "\n",
      "\n",
      "\n",
      "lifestyle1\n",
      "Number of articles: 399 \tNumber of clusters: 10\n",
      "First cultural programme starts in Srirangam\n",
      "TNSTC launches 46 new services\n",
      "Officials asked to gear up for rainy season\n",
      "Paddy area shrinking in delta districts, says study\n",
      "Ring in the New Year on a luxury train\n",
      "The PPP way to tap Tirumala tourist potential\n",
      "“Ensure all children aged below 5 get polio drops”\n",
      "Intensify dengue control measures, Centre tells Tamil Nadu\n",
      "AIIMS: Team inspects site in Chengalpet\n",
      "Centre seeks specific details on proposed AIIMS sites in Tamil Nadu\n",
      "3 IGPs among President’s police medal awardees\n",
      "Traditional Russian art on show\n",
      "Cancer institutes to be set up in four medical college hospitals\n",
      "TVMCH to be ready for renal transplantation surgeries\n",
      "“It is right time to act smart”\n",
      "A mix of many new faces and some old war horses\n",
      "5 held for chain-snatching\n",
      "In brief\n",
      "On smoking Pirana, Ahmedabad Municipal Corporation now sings biomining tune\n",
      "Study: Overuse contaminates groundwater in Tamil Nadu\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datasets = ['dataset_agriculture', 'dataset_development', 'dataset_environment', 'dataset_industrialization', 'dataset_lifestyle']\n",
    "models = ['model_agriculture', 'model_development', 'model_environment', 'model_industrialization', 'model_lifestyle']\n",
    "\n",
    "for dataset, model in zip(datasets,models):\n",
    "\n",
    "    # Printing the collection name.\n",
    "    collection_name = dataset[8:]\n",
    "    print('\\nCollection:',collection_name.capitalize())\n",
    "\n",
    "    # Loading the dataset and the model from the drive.\n",
    "    file = open('Datasets/'+dataset, 'rb')\n",
    "    dataset = pickle.loads(zlib.decompress(pickle.load(file)))\n",
    "    file.close()\n",
    "    model = Doc2Vec.load('Models/'+model)\n",
    "\n",
    "    # Collecting the article_ids, and corresponding article_vectors for each class.\n",
    "    temp_ids = [[] for _ in range(3)]\n",
    "    temp_vectors = [[] for _ in range(3)]\n",
    "    temp_datasets = [[] for _ in range(3)]\n",
    "    temp_titles = [[] for _ in range(3)]\n",
    "    for i in dataset:\n",
    "        if i[-5]==619: # thiruvarur 16-17 Unemp\n",
    "            if i[0] not in temp_ids[0]:\n",
    "                temp_ids[0].append(i[0])\n",
    "                temp_titles[0].append(i[1])\n",
    "                temp_vectors[0].append(model.docvecs[i[0]])\n",
    "                temp_datasets[0].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[-5]==620: #thanjavur 16-20 Unemp\n",
    "            if i[0] not in temp_ids[1]:\n",
    "                temp_ids[1].append(i[0])\n",
    "                temp_titles[1].append(i[1])\n",
    "                temp_vectors[1].append(model.docvecs[i[0]])\n",
    "                temp_datasets[1].append([i[0],model.docvecs[i[0]]])\n",
    "    \n",
    "    art1,art2,indA1,indA2,indx1,indx2 = get_pat_res(temp_vectors[0],temp_vectors[1])\n",
    "    titles1 = get_filtered(temp_titles[0],indx1,indA1,art1)\n",
    "    titles2 = get_filtered(temp_titles[1],indx2,indA2,art2)\n",
    "    rndm = sample([a for a in range(len(titles1))],min(len(titles1),10))\n",
    "    titles1 = [titles1[a] for a in rndm]\n",
    "    rndm = sample([a for a in range(len(titles2))],min(len(titles2),10))\n",
    "    titles2 = [titles2[a] for a in rndm]\n",
    "    for k in titles1:\n",
    "        print(k)\n",
    "    print('\\n\\n')\n",
    "    for k in titles2:\n",
    "        print(k)\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collection: Agriculture\n",
      "218\n",
      "agriculture0\n",
      "Number of articles: 218 \tNumber of clusters: 12\n",
      "Continuous ruckus in Odisha Assembly over farmer suicide\n",
      "Odisha BJP demands judicial probe into farm deaths\n",
      "No government relief to farmers who burnt pest-infected paddy crop in Odhisha\n",
      "Odisha government directs collectors of eight districts to submit report on crop loss\n",
      "BJD on farmer appeasement drive\n",
      "BJD to project pro-farmer image at Bargarh rally\n",
      "Farmer ends life over crop loss\n",
      "Day after setting fire to his crop, farmer commits suicide\n",
      "Farmer suicide: One dies, another survives bid\n",
      "Villagers force officials to reveal suicide findings\n",
      "Crop loss cause for 2 more farm deaths\n",
      "2 more farmers end lives in Bargarh due to crop loss\n",
      "BJP steps up protest over pest attack\n",
      "Pest Menace back to haunt Farmers in Sambalpur\n",
      "Jumbo scare\n",
      "Massive protests likely at Shivraj Singh Chauhan's public rally in Odisha on Saturday\n",
      "Modi to address farmer rally at Bargarh on Feb. 21\n",
      "Cong takes potshots at PM for silence on farmer suicides\n",
      "Government to procure Kharif paddy till April 30\n",
      "State sets 53L ton target for kharif\n",
      "\n",
      "\n",
      "\n",
      "agriculture1\n",
      "Number of articles: 56 \tNumber of clusters: 12\n",
      "Rain uplifts spirits on Nuakhai eve\n",
      "Nuakhai festival of western Odisha holds no charm for farmers\n",
      "Bird culling\n",
      "Pipili medical report \n",
      "BJD to protest Centre’s decision on paddy MSP\n",
      "Paddy purchase going on smoothly\n",
      "Odisha tillers block roads over crop payout\n",
      "Farmers take to the streets in Odisha\n",
      "Ethanol project in offing\n",
      "CM plays tribal card\n",
      "Good rainfall boosts farm activities in Odisha's Sambalpur\n",
      "No impact of deficit rain on farm works\n",
      "Killer tusker back in Angul, creates panic\n",
      "Jumbos wreak havoc on villages\n",
      "One tubewell for 60 families in Sambalpur district due to water scarcity\n",
      "A day at the vineyards\n",
      "Ragging charge on college students\n",
      "Defunct check dams add to farmers' woes in Odisha\n",
      "OSPCB overlooking Hindalco hazards: Environmentalists\n",
      "BJD, BJP slugfest over obstruction of Mahanadi water by Chhattisgarh\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collection: Development\n",
      "4\n",
      "development0\n",
      "Number of articles: 4 \tNumber of clusters: 4\n",
      "Workforce demand: Pradhan pins hopes on skill institute\n",
      "Naveen’s plea to Centre\n",
      "Sprinters make a mark\n",
      "Villagers unite to save boy with cancer\n",
      "\n",
      "\n",
      "\n",
      "development1\n",
      "Number of articles: 5 \tNumber of clusters: 5\n",
      "Sprinters make a mark\n",
      "Odia IAS officer Pramod Kumar Mishra takes over as Principal Secretary to Prime Minister\n",
      "Carrot-and-stick for rural job scheme\n",
      "BJP to put scam accused behind bars, says Pradhan\n",
      "Sizzling sun sears state\n",
      "\n",
      "\n",
      "\n",
      "Ashok Pradhan |\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collection: Environment\n",
      "49\n",
      "environment0\n",
      "Number of articles: 49 \tNumber of clusters: 11\n",
      "Malta fever\n",
      "Maoists destroy tower \n",
      "Maoist killed in forest encounter\n",
      "Maoist held in Bargarh\n",
      "Two cops held for man's custody death\n",
      "Cops held for custody death\n",
      "Leopard fear stalks Bargarh villagers\n",
      "Maoists torch vehicles in Sambalpur\n",
      "Odisha issues modalities for crop compensation\n",
      "Odisha 2017: A year of farmers' suicide, labour migration, industrial setback\n",
      "Master craftsman’s green ideas on bedspreads\n",
      "Sleuths nab retired OAS officer for land scam\n",
      "Odisha tiger died of septicemia, not poaching\n",
      "Akhilesh visit\n",
      "Tuskers stray into Debrigarh, spread panic among people\n",
      "Winter arrives late, birds stay away from Debrigarh\n",
      "8 killed in rain-triggered floods in Mizoram, North India still hot\n",
      "Wildlife workshop\n",
      "Row over Ong river dam construction\n",
      "Youth body seeks 'protected zone' tag for bauxite-rich Gandhamardhan\n",
      "\n",
      "\n",
      "\n",
      "environment1\n",
      "Number of articles: 81 \tNumber of clusters: 13\n",
      "Tusker menace back\n",
      "Jumbos kill 4 in Mayurbhanj & Sundargarh \n",
      "Jumbos wreak havoc on villages\n",
      "Killer jumbo back to haunt villagers\n",
      "Freak accident kills boy\n",
      "Boyanika\n",
      "Tourist spots\n",
      "2017 Odisha: A year of little cheer, more tragedy for Sambalpur\n",
      "NTPC, state PSU to set up thermal plant\n",
      "2 waterbodies to keep jumbos away\n",
      "SPCB flayed for permitting Hindalco to run two units of its CPP\n",
      "Pollution board asks thermal plants to stop spilling fly ash\n",
      "Dhanbad environment moratorium affects industrial sector\n",
      "34 of 37 Odisha Government hospitals run without valid Pollution Control Board certificate\n",
      "Maoists eye Satkosia to expand base\n",
      "Biodiversity tag for dam\n",
      "Naveen to start river campaign\n",
      "Check damage to crops caused by pollution: NHRC\n",
      "Sambalpur eye on bigger piece of tourism pie\n",
      "Sambalpur tourism spots fail to attract foreigners\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collection: Industrialization\n",
      "30\n",
      "industrialization0\n",
      "Number of articles: 30 \tNumber of clusters: 10\n",
      "BJD sweeps Attabira poll, bags 13 wards in Hindol\n",
      "A grim, tumultuous year for western Odisha\n",
      "BJD meet on strategy\n",
      "Naveen meets senior leaders of party twice in a week on Bijepur by-poll\n",
      "GSYP to take out ‘sahid yatra'\n",
      "Malta fever\n",
      "Youth body seeks 'protected zone' tag for bauxite-rich Gandhamardhan\n",
      "Bauxite mine\n",
      "Auction: No mine in state makes cut\n",
      "Centre asks state govt to expedite mining auction process\n",
      "Single window authority clears project worth Rs 15,000 crore\n",
      "13 projects worth J14,981 cr cleared\n",
      "Vista boss cheated of 3cr by builders\n",
      "Crores seized in assets raid\n",
      "Bengal textile institute soon \n",
      "3 Odias get Padma Shri\n",
      "Solar lanterns to be given to weavers\n",
      "Weaver woes loom large\n",
      "Singles in Bhubaneswar are hot property\n",
      "\n",
      "\n",
      "\n",
      "industrialization1\n",
      "Number of articles: 42 \tNumber of clusters: 11\n",
      "Bheden River faces threat due to industrialisation\n",
      "Dhanbad environment moratorium affects industrial sector\n",
      "SPCB directs closure of sponge iron unit\n",
      "PCB serves closure notice on BPSL\n",
      "Odisha's Single window authority clears projects worth Rs 25,474 crore\n",
      "Odisha CM Naveen Patnaik launches 22 projects worth Rs 4,461 crore\n",
      "Drone vigil in coal town\n",
      "Traffic curbs for Puja ease\n",
      "Environment study jogs attention to air pollution in west Odisha districts\n",
      "Western Odisha gasps for fresh air\n",
      "Naveen defends letter on Hindalco\n",
      "CBI interrogation cry for Naveen\n",
      "Varsity launches drive for backlog certificates\n",
      "Lawyers' stir raises a stink\n",
      "Life term for two in murder case\n",
      "Villagers oppose quartz mining\n",
      "Working women's hostels turn into offices\n",
      "Father shaves off head to repent daughter’s marriage\n",
      "ED spots Seashore land in Sambalpur\n",
      "Crores seized in assets raid\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collection: Lifestyle\n",
      "99\n",
      "lifestyle0\n",
      "Number of articles: 99 \tNumber of clusters: 12\n",
      "Minister’s brother  three others attacked\n",
      "Minister kin hurt in attack\n",
      "BJP misleading ryots: Rout\n",
      "Report out on farmers' death\n",
      "VSS deaths: Probe team gets Thursday deadline\n",
      "Bicycle pump used in Odisha sterilization operations\n",
      "Vista boss cheated of 3cr by builders\n",
      "Chit fund company director arrested\n",
      "Barabati dance fest begins today\n",
      "A band to bond with folk music\n",
      "Maoists destroy tower \n",
      "Wildlife workshop\n",
      "HC seeks reply for delay in bridge job\n",
      "Laddu auction\n",
      "State to develop thematic clusters under RURBAN\n",
      "Odisha Chief Minister Naveen Patnaik flags off pilgrimage train\n",
      "Breaking bonds of misery\n",
      "'Hangover of the yatra lingers'\n",
      "Central funds for state not properly used: Union minister\n",
      "Focus on cash crops, Union agri minister tells peasants\n",
      "\n",
      "\n",
      "\n",
      "lifestyle1\n",
      "Number of articles: 97 \tNumber of clusters: 10\n",
      "Shootout\n",
      "Bird culling\n",
      "Naveen reviews jaundice action\n",
      "Sambalpur eye on bigger piece of tourism pie\n",
      "Time for folk art festivals in districts\n",
      "Plan on to promote folk art forms\n",
      "9 newborns in Odisha  die within  24 hours\n",
      "9 kids die in two days in Odisha hospital; government orders probe\n",
      "Jharkhand to get Rs 100 crore for heritage sites\n",
      "Budharaja forest makeover plan on\n",
      "Surgeries stopped in Sambalpur Headquarters Hospital due to absence of anaesthetists\n",
      "Government code for ambulance service\n",
      "Death sentence for rape, murder of 8-year-old\n",
      "5 get life term for rape\n",
      "HC's Blue Whale directive to police\n",
      "App High Risk Mother Tracking helps bring down maternal mortality\n",
      "Ministers join yoga mission\n",
      "Toilet movie inspires mukhiyas\n",
      "UN aid chief Stephen O’Brien demands probe of Yemen wedding bombing\n",
      "UN aid chief demands probe of Yemen wedding bombing\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datasets = ['dataset_agriculture', 'dataset_development', 'dataset_environment', 'dataset_industrialization', 'dataset_lifestyle']\n",
    "models = ['model_agriculture', 'model_development', 'model_environment', 'model_industrialization', 'model_lifestyle']\n",
    "\n",
    "for dataset, model in zip(datasets,models):\n",
    "\n",
    "    # Printing the collection name.\n",
    "    collection_name = dataset[8:]\n",
    "    print('\\nCollection:',collection_name.capitalize())\n",
    "\n",
    "    # Loading the dataset and the model from the drive.\n",
    "    file = open('Datasets/'+dataset, 'rb')\n",
    "    dataset = pickle.loads(zlib.decompress(pickle.load(file)))\n",
    "    file.close()\n",
    "    model = Doc2Vec.load('Models/'+model)\n",
    "\n",
    "    # Collecting the article_ids, and corresponding article_vectors for each class.\n",
    "    temp_ids = [[] for _ in range(3)]\n",
    "    temp_vectors = [[] for _ in range(3)]\n",
    "    temp_datasets = [[] for _ in range(3)]\n",
    "    temp_titles = [[] for _ in range(3)]\n",
    "    for i in dataset:\n",
    "        if i[-4]==370: #Bargarh 10-9 Agri\n",
    "            if i[0] not in temp_ids[0]:\n",
    "                temp_ids[0].append(i[0])\n",
    "                temp_titles[0].append(i[1])\n",
    "                temp_vectors[0].append(model.docvecs[i[0]])\n",
    "                temp_datasets[0].append([i[0],model.docvecs[i[0]]])\n",
    "        if i[-4]==372: #Sambalpur 10-15 Agri\n",
    "            if i[0] not in temp_ids[1]:\n",
    "                temp_ids[1].append(i[0])\n",
    "                temp_titles[1].append(i[1])\n",
    "                temp_vectors[1].append(model.docvecs[i[0]])\n",
    "                temp_datasets[1].append([i[0],model.docvecs[i[0]]])\n",
    "    art1,art2,indA1,indA2,indx1,indx2 = get_pat_res(temp_vectors[0],temp_vectors[1])\n",
    "    titles1 = get_filtered(temp_titles[0],indx1,indA1,art1)\n",
    "    titles2 = get_filtered(temp_titles[1],indx2,indA2,art2)\n",
    "    rndm = sample([a for a in range(len(titles1))],min(len(titles1),10))\n",
    "    titles1 = [titles1[a] for a in rndm]\n",
    "    rndm = sample([a for a in range(len(titles2))],min(len(titles2),10))\n",
    "    titles2 = [titles2[a] for a in rndm]\n",
    "    for k in titles1:\n",
    "        print(k)\n",
    "    print('\\n\\n')\n",
    "    for k in titles2:\n",
    "        print(k)\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collection: Industrialization\n",
      "industrialization0\n",
      "Number of articles: 9 \tNumber of clusters: 8\n",
      "I-T searches on Jaipur-based businessman's 30 properties\n",
      "I-T raids on state BJP leader's premises\n",
      "In Rajasthan’s biggest haul, I-T finds Rs 105cr undisclosed income\n",
      "Industry upbeat on electronics zone, spl investment Act\n",
      "Raje govt to go ahead with distillery in Ganganagar\n",
      "Briefly Region; Haryana cop bags PMs medal for saving drowning drivers life\n",
      "Small comfort from spectrum cash\n",
      "Lack of agro-based supporting industry a major drawback\n",
      "In Pics:&thinsp;US mother traces son's final journey after study trip to Uttarakhand led...\n",
      "\n",
      "\n",
      "\n",
      "industrialization2\n",
      "Number of articles: 1833 \tNumber of clusters: 14\n",
      "New lease of life for water resources\n",
      "A clean-up act, literally\n",
      "Thakre reiterates opposition to power plants\n",
      "Political egos affecting vidarbha's fortunes\n",
      "Take Action against Mining Units without Clearances on Western Ghats, Centre Tells Maharashtra\n",
      "Warrant against MoEFCC director\n",
      "Businessmen pin hopes on Prabhu’s visit, to raise several demands\n",
      "Citizens demand better rail connectivity to city\n",
      "Rebel thickens the plot in Bikaner\n",
      "HDK promises water 'within  45 days of coming to power'\n",
      "Power cuts looming, farmers in Maharashtra prepare for the worst\n",
      "Country may end up with surplus sugar in 2012-13\n",
      "MoUs given to 145 entrepreneurs\n",
      "Maha biz summit ends with state signing MoUs worth Rs 12 lakh crore\n",
      "Ferry service: packagetours being worked out\n",
      "Tourist flow to HP increases\n",
      "World class capital will be built: Iswaran\n",
      "Capital project: The making of Amaravati\n",
      "Panel to visit South\n",
      "Meeting on minimum wages\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datasets = ['dataset_agriculture', 'dataset_development', 'dataset_environment', 'dataset_industrialization', 'dataset_lifestyle']\n",
    "models = ['model_agriculture', 'model_development', 'model_environment', 'model_industrialization', 'model_lifestyle']\n",
    "\n",
    "for dataset, model in zip(datasets[3:4],models[3:4]):\n",
    "\n",
    "    # Printing the collection name.\n",
    "    collection_name = dataset[8:]\n",
    "    print('\\nCollection:',collection_name.capitalize())\n",
    "\n",
    "    # Loading the dataset and the model from the drive.\n",
    "    file = open('Datasets/'+dataset, 'rb')\n",
    "    dataset = pickle.loads(zlib.decompress(pickle.load(file)))\n",
    "    file.close()\n",
    "    model = Doc2Vec.load('Models/'+model)\n",
    "\n",
    "    # Collecting the article_ids, and corresponding article_vectors for each class.\n",
    "    temp_ids = [[] for _ in range(3)]\n",
    "    temp_vectors = [[] for _ in range(3)]\n",
    "    temp_datasets = [[] for _ in range(3)]\n",
    "    temp_titles = [[] for _ in range(3)]\n",
    "    for i in dataset:\n",
    "        if i[-5]==99: # Ganganagar \n",
    "            if i[0] not in temp_ids[0]:\n",
    "                temp_ids[0].append(i[0])\n",
    "                temp_titles[0].append(i[1])\n",
    "                temp_vectors[0].append(model.docvecs[i[0]])\n",
    "                temp_datasets[0].append([i[0],model.docvecs[i[0]]])\n",
    "        elif i[-4]=='Agri' and i[-1]=='Fast':\n",
    "            if i[0] not in temp_ids[2]:\n",
    "                temp_ids[1].append(i[0])\n",
    "                temp_titles[1].append(i[1])\n",
    "                temp_vectors[1].append(model.docvecs[i[0]])\n",
    "                temp_datasets[1].append([i[0],model.docvecs[i[0]]])\n",
    "        \n",
    "    art1,art2,indA1,indA2,indx1,indx2 = get_pat_res(temp_vectors[0],temp_vectors[1])\n",
    "    titles1 = get_filtered(temp_titles[0],indx1,indA1,art1)\n",
    "    titles2 = get_filtered(temp_titles[1],indx2,indA2,art2)\n",
    "    rndm = sample([a for a in range(len(titles1))],min(len(titles1),10))\n",
    "    titles1 = [titles1[a] for a in rndm]\n",
    "    rndm = sample([a for a in range(len(titles2))],min(len(titles2),10))\n",
    "    titles2 = [titles2[a] for a in rndm]\n",
    "    for k in titles1:\n",
    "        print(k)\n",
    "    print('\\n\\n')\n",
    "    for k in titles2:\n",
    "        print(k)\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collection: Agriculture\n",
      "agriculture0\n",
      "Number of articles: 4 \tNumber of clusters: 3\n",
      "'Eye on Immense Potential', Uttarakhand Plans to Distil Badri Cow Urine, Sell It to Pharma Firms\n",
      "'Eye on immense potential', Uttarakhand plans to distil Badri cow urine, sell it...\n",
      "Rains brings death, loss to property and constant fear\n",
      "Tyre tubes, not poll promises, keep Lakhimpur villagers afloat\n",
      "\n",
      "\n",
      "\n",
      "agriculture2\n",
      "Number of articles: 3671 \tNumber of clusters: 14\n",
      "Met predicts more rain in coming days\n",
      "Heavy rains predicted in coming days\n",
      "Rain batters Mumbai, Thane, Pune and Nashik; swollen Godavari floods Andhra districts\n",
      "Flood crisis deepens in Gujarat, Rajasthan; PM&thinsp;Modi inspects home state, gives relief...\n",
      "Vegetable prices soar, milk supply hit as farmers’ protest for third day\n",
      "Ahead of Rabi crop, farmers in Bulandshahr rue lack of cash\n",
      "Farmer found murdered\n",
      "Dacoits kill two villagers, escape with booty\n",
      "Water released from Grand Anicut for irrigation in Cauvery delta\n",
      "Chances of opening Mettur dam on schedule appear remote\n",
      "Kanpur Municipal Corporation demolishes Illegal structures over nullahs\n",
      "Dug-up roads turn into death trap in monsoon\n",
      "Students get laptops with calls to make Mulayam Singh Yadav PM\n",
      "Cabinet ministers with criminal records in new government\n",
      "Twin cities in grip of viral fever\n",
      "Mystery fever still an enigma for health department\n",
      "Centre launches organic farming scheme in J&K\n",
      "Centre launches scheme to make J&K hub of aromatic and medicinal plants\n",
      "Date palm farming catching up fast in South Gujarat\n",
      "Jatropha not viable biofuel, scientists eye alternatives\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datasets = ['dataset_agriculture', 'dataset_development', 'dataset_environment', 'dataset_industrialization', 'dataset_lifestyle']\n",
    "models = ['model_agriculture', 'model_development', 'model_environment', 'model_industrialization', 'model_lifestyle']\n",
    "\n",
    "for dataset, model in zip(datasets[0:1],models[0:1]):\n",
    "\n",
    "    # Printing the collection name.\n",
    "    collection_name = dataset[8:]\n",
    "    print('\\nCollection:',collection_name.capitalize())\n",
    "\n",
    "    # Loading the dataset and the model from the drive.\n",
    "    file = open('../../Datasets/newADIdataset/'+dataset, 'rb')\n",
    "    dataset = pickle.loads(zlib.decompress(pickle.load(file)))\n",
    "    file.close()\n",
    "    model = Doc2Vec.load('../../Datasets/newADImodels/'+model)\n",
    "\n",
    "    # Collecting the article_ids, and corresponding article_vectors for each class.\n",
    "    temp_ids = [[] for _ in range(3)]\n",
    "    temp_vectors = [[] for _ in range(3)]\n",
    "    temp_datasets = [[] for _ in range(3)]\n",
    "    temp_titles = [[] for _ in range(3)]\n",
    "    for i in dataset:\n",
    "        if i[-5]==65: # Champawat \n",
    "            if i[0] not in temp_ids[0]:\n",
    "                temp_ids[0].append(i[0])\n",
    "                temp_titles[0].append(i[1])\n",
    "                temp_vectors[0].append(model.docvecs[i[0]])\n",
    "                temp_datasets[0].append([i[0],model.docvecs[i[0]]])\n",
    "        elif i[6]=='Unemp' and i[-1]=='Fast':\n",
    "            if i[0] not in temp_ids[2]:\n",
    "                temp_ids[1].append(i[0])\n",
    "                temp_titles[1].append(i[1])\n",
    "                temp_vectors[1].append(model.docvecs[i[0]])\n",
    "                temp_datasets[1].append([i[0],model.docvecs[i[0]]])\n",
    "        \n",
    "    art1,art2,indA1,indA2,indx1,indx2 = get_pat_res(temp_vectors[0],temp_vectors[1])\n",
    "    titles1 = get_filtered(temp_titles[0],indx1,indA1,art1)\n",
    "    titles2 = get_filtered(temp_titles[1],indx2,indA2,art2)\n",
    "    rndm = sample([a for a in range(len(titles1))],min(len(titles1),10))\n",
    "    titles1 = [titles1[a] for a in rndm]\n",
    "    rndm = sample([a for a in range(len(titles2))],min(len(titles2),10))\n",
    "    titles2 = [titles2[a] for a in rndm]\n",
    "    for k in titles1:\n",
    "        print(k)\n",
    "    print('\\n\\n')\n",
    "    for k in titles2:\n",
    "        print(k)\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collection: Lifestyle\n",
      "lifestyle0\n",
      "Number of articles: 28 \tNumber of clusters: 11\n",
      "Egypt declares 3-month state of emergency after twin bombings\n",
      "Blasts at Egypt's Coptic churches leave at least 44 dead, over 100 injured\n",
      "Egypt parliament approves three-month state of emergency\n",
      "Veil of insecurity shrouds Egypt\n",
      "Egypt President Abdel-Fattah al-Sisi declares three-month emergency\n",
      "23 Coptic Christians killed in Egypt attack\n",
      "Attack in Cairo kills three policemen, injures five\n",
      "Tension in Shahabad after desecration of portrait\n",
      "One Killed in UP's Sambhal Dist in Mob Violence over Child-Lifting Rumours, Cops Initiate Action\n",
      "The Rumour That Killed: Incidences of Mob Violence over Child-lifting Hoax on Rise in Uttar Pradesh\n",
      "In Yogi raj, men should keep their women indoors: Azam Khan on Rampur molestati...\n",
      "Govt push to update district chronicles\n",
      "4 arrested for transporter's murder\n",
      "Metamorphosis of a Village Girl into a Photography Icon\n",
      "\n",
      "\n",
      "\n",
      "lifestyle2\n",
      "Number of articles: 23695 \tNumber of clusters: 40\n",
      "Stone crushers fail to get relief from CM\n",
      "In a hole\n",
      "Swollen Ganga worries Nitish\n",
      "Bihar CM lists steps to increase footfall at VTR\n",
      "Mill attack\n",
      "Charge \n",
      "Jat stir: Fresh violence breaks out in Haryana, death toll 16\n",
      "Anti-riot force in all districts for Dussehra, Muharram\n",
      "MLA, 2 ex-MPs among 15 convicted of murder bid on DM, SP\n",
      "Rs 1cr for martyr's kin in Delhi\n",
      "Unease as RJD leader wants Lalu’s son Tejaswi to be elevated to Chief Minister\n",
      "Rabri rides for change to fill Lalu void\n",
      "Patna Medical College and Hospital, Indira Gandhi Institute of Medical Sciences doctors go on strike\n",
      " \n",
      "\n",
      "\n",
      "Two killed, many hurt in U.P. clashes\n",
      "CM Akhilesh’s riot scorecard: 5 in last 75 days,0 chargesheet\n",
      "Dal, RJD change tack to fight BJP\n",
      "Shivraj Singh Chouhan's opponent Arun Yadav confident of Congress sweeping MP Assembly polls\n",
      "19 criminals held in police crackdown\n",
      "Notorious truck looter arrested\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datasets = ['dataset_agriculture', 'dataset_development', 'dataset_environment', 'dataset_industrialization', 'dataset_lifestyle']\n",
    "models = ['model_agriculture', 'model_development', 'model_environment', 'model_industrialization', 'model_lifestyle']\n",
    "\n",
    "for dataset, model in zip(datasets[4:],models[4:]):\n",
    "\n",
    "    # Printing the collection name.\n",
    "    collection_name = dataset[8:]\n",
    "    print('\\nCollection:',collection_name.capitalize())\n",
    "\n",
    "    # Loading the dataset and the model from the drive.\n",
    "    file = open('Datasets/'+dataset, 'rb')\n",
    "    dataset = pickle.loads(zlib.decompress(pickle.load(file)))\n",
    "    file.close()\n",
    "    model = Doc2Vec.load('Models/'+model)\n",
    "\n",
    "    # Collecting the article_ids, and corresponding article_vectors for each class.\n",
    "    temp_ids = [[] for _ in range(3)]\n",
    "    temp_vectors = [[] for _ in range(3)]\n",
    "    temp_datasets = [[] for _ in range(3)]\n",
    "    temp_titles = [[] for _ in range(3)]\n",
    "    for i in dataset:\n",
    "        if i[-5]==136: #Rampur \n",
    "            if i[0] not in temp_ids[0]:\n",
    "                temp_ids[0].append(i[0])\n",
    "                temp_titles[0].append(i[1])\n",
    "                temp_vectors[0].append(model.docvecs[i[0]])\n",
    "                temp_datasets[0].append([i[0],model.docvecs[i[0]]])\n",
    "        elif i[6]=='Unemp' and i[-1]=='Slow':\n",
    "            if i[0] not in temp_ids[2]:\n",
    "                temp_ids[1].append(i[0])\n",
    "                temp_titles[1].append(i[1])\n",
    "                temp_vectors[1].append(model.docvecs[i[0]])\n",
    "                temp_datasets[1].append([i[0],model.docvecs[i[0]]])\n",
    "        \n",
    "    art1,art2,indA1,indA2,indx1,indx2 = get_pat_res(temp_vectors[0],temp_vectors[1])\n",
    "    titles1 = get_filtered(temp_titles[0],indx1,indA1,art1)\n",
    "    titles2 = get_filtered(temp_titles[1],indx2,indA2,art2)\n",
    "    rndm = sample([a for a in range(len(titles1))],min(len(titles1),10))\n",
    "    titles1 = [titles1[a] for a in rndm]\n",
    "    rndm = sample([a for a in range(len(titles2))],min(len(titles2),10))\n",
    "    titles2 = [titles2[a] for a in rndm]\n",
    "    for k in titles1:\n",
    "        print(k)\n",
    "    print('\\n\\n')\n",
    "    for k in titles2:\n",
    "        print(k)\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collection: Agriculture\n",
      "agriculture0\n",
      "Number of articles: 13 \tNumber of clusters: 10\n",
      "Monsoon to reach Kerala in next 48 hours\n",
      "Cyclonic storm building over Arabian Sea, says Met dept\n",
      "Monsoon likely to hit Kerala in 4 days: IMD\n",
      "Monsoon advances after lying low for over a week\n",
      "Mumbai receives pre-monsoon showers, dust storm brings down temperature in North India\n",
      "23 including women killed in rain, lightening-related incidents in Bihar\n",
      "Conditions favourable for onset of monsoon: IMD\n",
      "Monsoon hits Kerala three days early\n",
      "Dry weather reported in TN, K'taka\n",
      "Below average monsoon likely in other parts too\n",
      "Rain lashes Kerala; Holiday for schools, colleges tomorrow\n",
      "Pollution turning country's rainfall acidic, says study\n",
      "Working women and working men – A country divided\n",
      "\n",
      "\n",
      "\n",
      "agriculture2\n",
      "Number of articles: 4594 \tNumber of clusters: 17\n",
      "Vector alarm sounded at heal hubs\n",
      "Man, machine take on diseased city \n",
      "Kulathummal Canal gets a fillip to improve and restore the soil quality\n",
      "Stress laid on cleaning up rivers from their origin\n",
      "Rains to reign after 72hrs\n",
      "Brace for brolly good show this week\n",
      "Brahmavar to host two-day Krishi mela from tomorrow\n",
      "New project to improve vegetable production\n",
      "It’s still a treacherous stretch\n",
      "Konkan railway route timings to change from June 10\n",
      "Mishap\n",
      "It’s back to Dalma for marauding herd  \n",
      "Team inspects Mettur, Bhavanisagar dams\n",
      "‘Declare Salem as drought hit’\n",
      "Nature's fury hits normal life\n",
      "Karnataka rains: Orange and red alert across Mysuru, Pune-Bengaluru stretch of NH 48 closed\n",
      "Farmers cheerful, as field price of nendran banana goes up\n",
      "Festival demand pushes flower prices up\n",
      "Monsoon on campus: A soggy walk down memory lane\n",
      "One year on, city's landmark road a crumbly mess\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datasets = ['dataset_agriculture', 'dataset_development', 'dataset_environment', 'dataset_industrialization', 'dataset_lifestyle']\n",
    "models = ['model_agriculture', 'model_development', 'model_environment', 'model_industrialization', 'model_lifestyle']\n",
    "\n",
    "for dataset, model in zip(datasets[0:1],models[0:1]):\n",
    "\n",
    "    # Printing the collection name.\n",
    "    collection_name = dataset[8:]\n",
    "    print('\\nCollection:',collection_name.capitalize())\n",
    "\n",
    "    # Loading the dataset and the model from the drive.\n",
    "    file = open('Datasets/'+dataset, 'rb')\n",
    "    dataset = pickle.loads(zlib.decompress(pickle.load(file)))\n",
    "    file.close()\n",
    "    model = Doc2Vec.load('Models/'+model)\n",
    "\n",
    "    # Collecting the article_ids, and corresponding article_vectors for each class.\n",
    "    temp_ids = [[] for _ in range(3)]\n",
    "    temp_vectors = [[] for _ in range(3)]\n",
    "    temp_datasets = [[] for _ in range(3)]\n",
    "    temp_titles = [[] for _ in range(3)]\n",
    "    for i in dataset:\n",
    "        if i[-5]==587: # Lakshdeep \n",
    "            if i[0] not in temp_ids[0]:\n",
    "                temp_ids[0].append(i[0])\n",
    "                temp_titles[0].append(i[1])\n",
    "                temp_vectors[0].append(model.docvecs[i[0]])\n",
    "                temp_datasets[0].append([i[0],model.docvecs[i[0]]])\n",
    "        elif i[-4]=='Non Agri' and i[-1]=='Slow':\n",
    "            if i[0] not in temp_ids[2]:\n",
    "                temp_ids[1].append(i[0])\n",
    "                temp_titles[1].append(i[1])\n",
    "                temp_vectors[1].append(model.docvecs[i[0]])\n",
    "                temp_datasets[1].append([i[0],model.docvecs[i[0]]])\n",
    "    \n",
    "    art1,art2,indA1,indA2,indx1,indx2 = get_pat_res(temp_vectors[0],temp_vectors[1])\n",
    "    titles1 = get_filtered(temp_titles[0],indx1,indA1,art1)\n",
    "    titles2 = get_filtered(temp_titles[1],indx2,indA2,art2)\n",
    "    rndm = sample([a for a in range(len(titles1))],min(len(titles1),10))\n",
    "    titles1 = [titles1[a] for a in rndm]\n",
    "    rndm = sample([a for a in range(len(titles2))],min(len(titles2),10))\n",
    "    titles2 = [titles2[a] for a in rndm]\n",
    "    for k in titles1:\n",
    "        print(k)\n",
    "    print('\\n\\n')\n",
    "    for k in titles2:\n",
    "        print(k)\n",
    "    print('\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
