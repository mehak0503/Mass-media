{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle, zlib\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "import gensim\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from gensim import corpora, models\n",
    "from collections import Counter\n",
    "# Show graph\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from numpy import array\n",
    "import gensim.corpora as corpora\n",
    "import random\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_values(d):\n",
    "    #map districtid label to names\n",
    "    df = pd.read_excel('Files/ADI.xlsx')\n",
    "    census = list(df['census_code'])\n",
    "    dist_names = list(df['name'])\n",
    "    keyss = list(d.keys())\n",
    "    values = [i for i in keyss]\n",
    "    for i in range(len(keyss)):\n",
    "        if keyss[i] in census:\n",
    "            values[i] = dist_names[census.index(keyss[i])]\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find median vector for each district\n",
    "from collections import defaultdict\n",
    "import statistics \n",
    "def find_median(vecs):\n",
    "    for i in range(50):\n",
    "        med.append(statistics.median(arr[:,i]))\n",
    "    return med\n",
    "\n",
    "def ret_val():\n",
    "    return []\n",
    "\n",
    "def get_vectors(temp_vector,temp_distt):\n",
    "    d = defaultdict(ret_val)\n",
    "    for i in range(len(temp_vector)):\n",
    "        d[temp_distt[i]].append(temp_vector[i])\n",
    "\n",
    "    vectors = []\n",
    "    for i in d.keys():\n",
    "        vectors.append(np.array(find_median(d[i])))\n",
    "    return d,vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret_val_2():\n",
    "    return None\n",
    "\n",
    "def get_vectors_dist(temp_vector,temp_distt):\n",
    "    d = defaultdict(ret_val_2)\n",
    "    for i in range(len(temp_vector)):\n",
    "        d[temp_distt[i]]=(temp_vector[i])\n",
    "\n",
    "    vectors = []\n",
    "    for i in d.keys():\n",
    "        vectors.append(np.array(d[i]))\n",
    "    return d,vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Means Clustering - Elbow curve.\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans \n",
    "from sklearn import metrics \n",
    "from scipy.spatial.distance import cdist\n",
    "#X = np.array(vectors)\n",
    "# T-sne based on articles\n",
    "import seaborn as sns\n",
    "\n",
    "def kmeans(vectors):\n",
    "    X_embedded = TSNE(n_components=2).fit_transform(np.array(vectors))\n",
    "    #pca = PCA(n_components=2)\n",
    "    #principalComponents = pca.fit_transform(np.array(vectors))\n",
    "    #X = principalComponents\n",
    "    X = X_embedded\n",
    "    '''distortions = [] \n",
    "    inertias = [] \n",
    "    mapping1 = {} \n",
    "    mapping2 = {} \n",
    "    K = range(1,10) \n",
    "\n",
    "    for k in K: \n",
    "        #Building and fitting the model \n",
    "        kmeanModel = KMeans(n_clusters=k).fit(X)  \n",
    "\n",
    "        distortions.append(sum(np.min(cdist(X, kmeanModel.cluster_centers_, 'euclidean'),axis=1)) / X.shape[0]) \n",
    "        inertias.append(kmeanModel.inertia_) \n",
    "\n",
    "        mapping1[k] = sum(np.min(cdist(X, kmeanModel.cluster_centers_, \n",
    "                     'euclidean'),axis=1)) / X.shape[0] \n",
    "        mapping2[k] = kmeanModel.inertia_ \n",
    "\n",
    "    plt.plot(K, distortions, 'bx-') \n",
    "    plt.xlabel('Values of K') \n",
    "    plt.ylabel('Distortion') \n",
    "    plt.title('The Elbow Method using Distortion') \n",
    "    plt.show()\n",
    "    '''\n",
    "    labels = KMeans(n_clusters=3).fit(X).labels_\n",
    "    \n",
    "    return X,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mplcursors\n",
    "def plot_cluster(X,labels,values,titletext,path,l=False):\n",
    "    fig, ax = plt.subplots()\n",
    "    if l:\n",
    "        ax.scatter(X[:, 0], X[:, 1], c=labels,s=100, cmap='viridis')\n",
    "    else:\n",
    "        ax.scatter(X[:, 0], X[:, 1],s=100)\n",
    "    plt.title(titletext)\n",
    "    xx = list(X[:, 0])\n",
    "    yy = list(X[:, 1])\n",
    "    mplcursors.cursor(multiple = True).connect(\n",
    "        \"add\", lambda sel: sel.annotation.set_text(\n",
    "              values[sel.target.index]\n",
    "    ))\n",
    "    \n",
    "    old_x = old_y = 1e9 # make an impossibly large initial offset\n",
    "    thresh = .1 #make a distance threshold\n",
    "\n",
    "    '''for label, x, y in zip(values, X[:, 0], X[:, 1]):\n",
    "        #calculate distance\n",
    "        d = ((x-old_x)**2+(y-old_y)**2)**(.5)\n",
    "\n",
    "        #if distance less than thresh then flip the arrow\n",
    "        flip = 1\n",
    "        if d < .1: flip=-2\n",
    "\n",
    "        plt.annotate(\n",
    "            label,\n",
    "            xy = (x, y), xytext = (-20*flip, 20*flip),\n",
    "            textcoords = 'offset points', ha = 'right', va = 'bottom',\n",
    "            bbox = dict(boxstyle = 'round,pad=0.5', fc = 'yellow', alpha = 0.5),\n",
    "            arrowprops = dict(arrowstyle = '->', connectionstyle = 'arc3,rad=0'))\n",
    "        old_x = x\n",
    "        old_y = y\n",
    "    '''\n",
    "    \n",
    "    if l:\n",
    "        for i, txt in enumerate(values):\n",
    "            ax.annotate(txt,(xx[i], yy[i]))\n",
    "    plt.show()\n",
    "    #plt.savefig(path+titletext+'.png')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "datasets = ['dataset_agriculture', 'dataset_development', 'dataset_environment', 'dataset_industrialization', 'dataset_lifestyle']\n",
    "models = ['model_agriculture', 'model_development', 'model_environment', 'model_industrialization', 'model_lifestyle']\n",
    "\n",
    "for dataset, model in zip(datasets,models):\n",
    "\n",
    "    # Printing the collection name.\n",
    "    collection_name = dataset[8:]\n",
    "    print('\\nCollection:',collection_name.capitalize())\n",
    "\n",
    "    # Loading the dataset and the model from the drive.\n",
    "    file = open('Datasets/'+dataset, 'rb')\n",
    "    dataset = pickle.loads(zlib.decompress(pickle.load(file)))\n",
    "    file.close()\n",
    "    model = Doc2Vec.load('Models/'+model)\n",
    "\n",
    "    # Collecting the article_ids, and corresponding article_vectors for each class.\n",
    "    temp_ids = [[] for _ in range(9)]\n",
    "    temp_dist = [[] for _ in range(9)]\n",
    "    temp_titles = [[] for _ in range(9)]\n",
    "    temp_vectors = [[] for _ in range(9)]\n",
    "    temp_datasets = [[] for _ in range(9)]\n",
    "    for i in dataset:\n",
    "        if i[6]=='Unemp' and i[-1]=='Average':\n",
    "            if i[0] not in temp_ids[0]:\n",
    "                temp_ids[0].append(i[0])\n",
    "                temp_dist[0].append(i[-5])\n",
    "                temp_titles[0].append(i[1])\n",
    "                temp_vectors[0].append(model.docvecs[i[0]])\n",
    "        if i[6]=='Unemp' and i[-1]=='Slow':\n",
    "            if i[0] not in temp_ids[1]:\n",
    "                temp_ids[1].append(i[0])\n",
    "                temp_dist[1].append(i[-5])\n",
    "                temp_titles[1].append(i[1])\n",
    "                temp_vectors[1].append(model.docvecs[i[0]])\n",
    "        if i[6]=='Unemp' and i[-1]=='Fast':\n",
    "            if i[0] not in temp_ids[2]:\n",
    "                temp_ids[2].append(i[0])\n",
    "                temp_dist[2].append(i[-5])\n",
    "                temp_titles[2].append(i[1])\n",
    "                temp_vectors[2].append(model.docvecs[i[0]])\n",
    "        if i[6]=='Agri' and i[-1]=='Average':\n",
    "            if i[0] not in temp_ids[3]:\n",
    "                temp_ids[3].append(i[0])\n",
    "                temp_dist[3].append(i[-5])\n",
    "                temp_titles[3].append(i[1])\n",
    "                temp_vectors[3].append(model.docvecs[i[0]])\n",
    "        if i[6]=='Agri' and i[-1]=='Slow':\n",
    "            if i[0] not in temp_ids[4]:\n",
    "                temp_ids[4].append(i[0])\n",
    "                temp_dist[4].append(i[-5])\n",
    "                temp_titles[4].append(i[1])\n",
    "                temp_vectors[4].append(model.docvecs[i[0]])\n",
    "        if i[6]=='Agri' and i[-1]=='Fast':\n",
    "            if i[0] not in temp_ids[5]:\n",
    "                temp_ids[5].append(i[0])\n",
    "                temp_dist[5].append(i[-5])\n",
    "                temp_titles[5].append(i[1])\n",
    "                temp_vectors[5].append(model.docvecs[i[0]])\n",
    "        if i[6]=='Non Agri' and i[-1]=='Average':\n",
    "            if i[0] not in temp_ids[6]:\n",
    "                temp_ids[6].append(i[0])\n",
    "                temp_dist[6].append(i[-5])\n",
    "                temp_titles[6].append(i[1])\n",
    "                temp_vectors[6].append(model.docvecs[i[0]])\n",
    "        if i[6]=='Non Agri' and i[-1]=='Slow':\n",
    "            if i[0] not in temp_ids[7]:\n",
    "                temp_ids[7].append(i[0])\n",
    "                temp_dist[7].append(i[-5])\n",
    "                temp_titles[7].append(i[1])\n",
    "                temp_vectors[7].append(model.docvecs[i[0]])\n",
    "        if i[6]=='Non Agri' and i[-1]=='Fast':\n",
    "            if i[0] not in temp_ids[8]:\n",
    "                temp_ids[8].append(i[0])\n",
    "                temp_dist[8].append(i[-5])\n",
    "                temp_titles[8].append(i[1])\n",
    "                temp_vectors[8].append(model.docvecs[i[0]])\n",
    "    names = ['average growing unemployment districts','slow growing unemployment districts','fast growing unemployment districts',\\\n",
    "             'average growing agricultural districts','slow growing agricultural districts','fast growing agricultural districts',\\\n",
    "            'average growing non-agricultural districts','slow growing non-agricultural districts','fast growing non-agricultural districts']\n",
    "    for i in range(9):\n",
    "        titlee = 'Tsne '+names[i]+' in '+ collection_name + ' collection'\n",
    "        #d,vectors = get_vectors(temp_vectors[i],temp_dist[i])\n",
    "        distt = []\n",
    "        vector = []\n",
    "        for v in list(set(temp_dist[i])):\n",
    "            distt.append(v)\n",
    "            vector.append(model.docvecs[v])\n",
    "        d,vectors = get_vectors_dist(vector,distt)       \n",
    "        val = get_values(d)\n",
    "        X,labels=kmeans(vectors)\n",
    "        print(titlee,Counter(labels),val)\n",
    "        path = 'clusters/'\n",
    "        plot_cluster(X,labels,val,titlee,path,True)\n",
    "        plot_cluster(X,labels,val,'Un '+titlee,path)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
